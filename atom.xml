<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yet Another Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.oxymorus.com/"/>
  <updated>2019-10-07T22:39:55.000Z</updated>
  <id>https://www.oxymorus.com/</id>
  
  <author>
    <name>Oleksii Zghurskyi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka Provision Spring Boot Starter</title>
    <link href="https://www.oxymorus.com/kafka-provision-spring-boot-starter/"/>
    <id>https://www.oxymorus.com/kafka-provision-spring-boot-starter/</id>
    <published>2019-10-07T22:39:55.000Z</published>
    <updated>2019-10-07T22:39:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p><a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a> enables distributed Kafka topics provisioning and centralized topic configs management.</p></div><a id="more"></a><div class="sect1"><h2>Overview</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a> supports following set of features:</p></div><div class="ulist"><ul><li><p>creating new topics</p></li><li><p>adding partitions to the existing topics</p></li><li><p>setting/updating topic configurations</p></li></ul></div><div class="paragraph"><p>In this post I will describe the process of creating application, that uses the starter.</p></div></div></div><div class="sect1"><h2>Demo application description</h2><div class="sectionbody"><div class="paragraph"><p>To not overshadow main goal, the demo application will be really simple. We will create 2 "microservices":</p></div><div class="ulist"><ul><li><p>The first service will produce tasks and push them to the <code>tasks</code> topic</p></li><li><p>The second service will pull the tasks from the topic, sleep randomly and send events to <code>results</code> topic</p></li></ul></div><div class="paragraph"><p>So, everything sounds really simple - let&#8217;s overengineer it as much as possible!</p></div></div></div><div class="sect1"><h2>Setting up basic Spring Boot services</h2><div class="sectionbody"><div class="paragraph"><p>First, let&#8217;s bootstrap Spring Boot app with Spring Cloud Stream, Spring Kafka and Lombok support:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ curl https://start.spring.io/starter.zip \-d dependencies=cloud-stream,kafka,lombok \-d type=gradle-project \-d baseDir=task-producer \-d groupId=com.oxymorus.kafka.producer \-d artifactId=task-producer \-o task-producer.zip$ unzip task-producer.zip &amp;&amp; rm task-producer.zip</code></pre></div></div><div class="paragraph"><p>Just a quick note: Spring Cloud Stream is a framework for building highly scalable event-driven microservices connected with shared messaging systems.</p></div><div class="paragraph"><p>The core building blocks of Spring Cloud Stream are:</p></div><div class="ulist"><ul><li><p>Destination Binders: Components responsible to provide integration with the external messaging systems.</p></li><li><p>Destination Bindings: Bridge between the external messaging systems and application provided Producers and Consumers of messages (created by the Destination Binders).</p></li><li><p>Message: The canonical data structure used by producers and consumers to communicate with Destination Binders (and thus other applications via external messaging systems).</p></li></ul></div><div class="paragraph"><p>To get more detail just read the official reference <a href="https://cloud.spring.io/spring-cloud-static/spring-cloud-stream/2.1.2.RELEASE/single/spring-cloud-stream.html#_main_concepts" target="_blank" rel="noopener">here.</a></p></div><div class="paragraph"><p>Ok, let&#8217;s get back to our main course and bootstrap task-consumer service:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ curl https://start.spring.io/starter.zip -d dependencies=cloud-stream,kafka,lombok \-d type=gradle-project \-d baseDir=task-consumer \-d groupId=com.oxymorus.kafka.consumer \-d artifactId=task-consumer \-o task-consumer.zip$ unzip task-consumer.zip &amp;&amp; rm task-consumer.zip</code></pre></div></div></div></div><div class="sect1"><h2>Configuring Kafka topics</h2><div class="sectionbody"><div class="paragraph"><p>As described earlier two created services will communicate over Kafka topics: <code>tasks</code> and <code>results</code>. So, we need to create &amp; configure these topics. Here, comes the time for <a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a>.</p></div><div class="paragraph"><p>We will do this in three steps:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Add dependency</p></li><li><p>Add @EnableTopicProvisioning</p></li><li><p>Configure topics</p></li></ol></div><div class="paragraph"><p>Let&#8217;s do this procedure step-by-step for task-producer service. First, let&#8217;s add dependency to build.gradle:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">dependencies {    implementation 'io.github.zghurskyi.kafka:kafka-provision-spring-boot-starter:0.0.1'}</code></pre></div></div><div class="paragraph"><p>Next, let&#8217;s add @EnableTopicProvisioning to TaskProducerApp class:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.oxymorus.kafka.producer;import io.github.zghurskyi.kafka.EnableTopicProvisioning;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication@EnableTopicProvisioningpublic class TaskProducerApp {  public static void main(String[] args) {    SpringApplication.run(TaskProducerApp.class, args);  }}</code></pre></div></div><div class="paragraph"><p>And finally, let&#8217;s configure required topics:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka.provision:  brokers: localhost:9092  topics:  - name: tasks    numPartitions: 4    replicationFactor: 1    configs:      cleanup.policy: delete      retention.ms: 3600000  - name: results    numPartitions: 4    replicationFactor: 1    configs:      cleanup.policy: delete      retention.ms: 3600000</code></pre></div></div><div class="paragraph"><p>The above steps are similar for <code>task-consumer</code> service.</p></div><div class="paragraph"><p>The details of setting up Spring Cloud Stream &amp; Kafka in Spring Boot app deserve separate blog post, so to just stay on point I will skip them. You can find completed demo app <a href="https://github.com/zghurskyi/kafka-provision-examples" target="_blank" rel="noopener">here</a>.</p></div></div></div><div class="sect1"><h2>Setting up Kafka infrastructure</h2><div class="sectionbody"><div class="paragraph"><p>For the purposes of this demo we set up infrastructure with following docker-compose.yml:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">version: '3'services:    kafka:        image: confluentinc/cp-kafka:latest        container_name: kafka        ports:        - "9092:9092"        depends_on:        - zookeeper        environment:          KAFKA_BROKER_ID: 1          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1          KAFKA_MESSAGE_MAX_BYTES: 10000000    zookeeper:        image: confluentinc/cp-zookeeper:latest        container_name: zookeeper        ports:        - "2181:2181"        environment:          ZOOKEEPER_CLIENT_PORT: 2181          ZOOKEEPER_TICK_TIME: 2000          ZOOKEEPER_INIT_LIMIT: 5          ZOOKEEPER_SYNC_LIMIT: 2</code></pre></div></div></div></div><div class="sect1"><h2>Putting everything together</h2><div class="sectionbody"><div class="paragraph"><p>The time has come to start everything up:</p></div><div class="ulist"><ul><li><p>Boot up Kafka with docker-compose.yml:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ cd kafka-provision-examples/$ docker-compose up</code></pre></div></div><div class="ulist"><ul><li><p>Build and start <code>task-producer</code>:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ ./task-producer/gradlew -b ./task-producer/build.gradle clean build$ java -jar task-producer/build/libs/task-producer-0.0.1-SNAPSHOT.jar</code></pre></div></div><div class="ulist"><ul><li><p>Build and start <code>task-consumer</code>:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ ./task-consumer/gradlew -b ./task-consumer/build.gradle clean build$ java -jar task-consumer/build/libs/task-consumer-0.0.1-SNAPSHOT.jar</code></pre></div></div><div class="paragraph"><p>After starting everything up, we will see something like this in the logs:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-logs hljs" data-lang="logs">task_producer    | 2019-04-21 10:27:49.071  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=EAT, status=SUCCESS)task_producer    | 2019-04-21 10:27:49.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Published: TaskMessage(task=Task(action=SLEEP))task_producer    | 2019-04-21 10:27:49.413  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=WRITE_CODE, status=SUCCESS)task_producer    | 2019-04-21 10:27:50.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Published: TaskMessage(task=Task(action=SLEEP))task_producer    | 2019-04-21 10:27:50.826  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=EAT, status=FAIL)task_producer    | 2019-04-21 10:27:52.945  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=SLEEP, status=SKIP_THIS_TIME)task_producer    | 2019-04-21 10:27:53.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Received: ResultMessage(action=WRITE_CODE, status=SUCCESS)</code></pre></div></div><div class="paragraph"><p>This indicates, that everything works as it&#8217;s supposed to :)</p></div></div></div><div class="sect1"><h2>Checking topics configuration</h2><div class="sectionbody"><div class="paragraph"><p>Now let&#8217;s checkout Kafka topic configs, that were provisioned by starter:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-logs hljs" data-lang="logs">$ docker exec -ti kafka /bin/bashroot@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --list__confluent.support.metrics__consumer_offsetsresultstasksroot@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --describe --topic tasksTopic:tasks    PartitionCount:4    ReplicationFactor:1    Configs:retention.ms=360000,cleanup.policy=deleteTopic: tasks    Partition: 0    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 1    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 2    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 3    Leader: 1    Replicas: 1    Isr: 1root@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --describe --topic resultsTopic:results    PartitionCount:4    ReplicationFactor:1    Configs:retention.ms=360000,cleanup.policy=deleteTopic: results    Partition: 0    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 1    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 2    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 3    Leader: 1    Replicas: 1    Isr: 1</code></pre></div></div><div class="paragraph"><p>So, as we can see Kafka Provision Spring boot starter has created required topics for us and added specified configs.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/zghurskyi/kafka-provision-spring-boot-starter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Kafka Provision Spring Boot Starter&lt;/a&gt; enables distributed Kafka topics provisioning and centralized topic configs management.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Apache Kafka" scheme="https://www.oxymorus.com/categories/apache-kafka/"/>
    
      <category term="Spring Boot Starter" scheme="https://www.oxymorus.com/categories/apache-kafka/spring-boot-starter/"/>
    
      <category term="Topic Provisioning" scheme="https://www.oxymorus.com/categories/apache-kafka/spring-boot-starter/topic-provisioning/"/>
    
    
      <category term="Apache Kafka" scheme="https://www.oxymorus.com/tags/apache-kafka/"/>
    
      <category term="Spring Boot Starter" scheme="https://www.oxymorus.com/tags/spring-boot-starter/"/>
    
      <category term="Topic Provisioning" scheme="https://www.oxymorus.com/tags/topic-provisioning/"/>
    
  </entry>
  
  <entry>
    <title>Optimistic locking with Aerospike and Project Reactor</title>
    <link href="https://www.oxymorus.com/optimistic-locking-with-reactor-and-aerospike/"/>
    <id>https://www.oxymorus.com/optimistic-locking-with-reactor-and-aerospike/</id>
    <published>2019-10-06T19:47:51.000Z</published>
    <updated>2019-10-06T19:47:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to implement optimistic locking with Aerospike and Project Reactor ?</p></div><a id="more"></a><div class="sect1"><h2>Introduction</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/optimisticOfflineLock.html" target="_blank" rel="noopener">Optimistic locking</a> is general pattern commonly used to maintain data consistency.</p></div><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://martinfowler.com/eaaCatalog/OptimisticSketch.gif" target="_blank" rel="noopener"><img src="https://martinfowler.com/eaaCatalog/OptimisticSketch.gif" alt="OptimisticSketch"></a></div></div><div class="paragraph"><p>In this post I will describe how to implement optimistic locking with No-SQL storage, that has reactive client.</p></div><div class="sect2"><h3>Aerospike <code>generation</code> meta-data</h3><div class="paragraph"><p>In traditional RDBMS to implement optimistic locking one would have to introduce additional <code>version</code> or <code>timestamp</code> column.</p></div><div class="paragraph"><p>In case of Aerospike, required data is available by default: each record has <code>generation</code> meta-data. So, in order to fail, when record is updated/deleted concurrently, one would need only enable <code>GenerationPolicy.EXPECT_GEN_EQUAL</code>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ClientPolicy clientPolicy = new ClientPolicy();clientPolicy.writePolicyDefault.generationPolicy = GenerationPolicy.EXPECT_GEN_EQUAL;</code></pre></div></div><div class="paragraph"><p>Having above config in place ensures that update/delete will be executed successfully, if expected generation is equal to server generation, otherwise, update/delete will fail.</p></div></div><div class="sect2"><h3>Reactor <code>retryWhen</code> operation</h3><div class="paragraph"><p><a href="https://projectreactor.io/" target="_blank" rel="noopener">Project Reactor</a> is a fourth-generation Reactive library for building non-blocking applications on the JVM based on the <a href="https://github.com/reactive-streams/reactive-streams-jvm" target="_blank" rel="noopener">Reactive Streams Specification</a>.</p></div><div class="paragraph"><p>In the context of our goal, we will use <a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html#retryWhen-java.util.function.Function-" target="_blank" rel="noopener">retryWhen</a> operation:</p></div><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/doc-files/marbles/retryWhenForMono.svg" target="_blank" rel="noopener"><img src="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/doc-files/marbles/retryWhenForMono.svg" alt="retryWhenForMono"></a></div></div></div><div class="sect2"><h3>Implementation</h3><div class="paragraph"><p>Now let&#8217;s put everything together and write method that performs <code>createOrUpdate</code> operation on <code>Data</code> instance:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public Mono&lt;Data&gt; createOrUpdate(Data data) {    return Mono.defer(() -&gt; doCreateOrUpdate(data))            .retryWhen(Retries.optimisticLockException(retryProperties)                    .doOnRetry(context -&gt; log.warn("Retrying optimistic failure for data", data, context.exception()))            );}private Mono&lt;Data&gt; doCreateOrUpdate(Data data) {    return repository.findDataByKey(data.getKey())            .map(existingData -&gt; data.withGeneration(existingData.getGeneration()))            .flatMap(existingData -&gt; repository.createOrUpdate(existingData).map(Functions.constant(existingData)));}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Implementing optimistic locking with Aerospike and Reactor is pretty straight-forward. Since all tools are already in place, all that needs to be done - put everything together.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to implement optimistic locking with Aerospike and Project Reactor ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/categories/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/"/>
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/optimistic-locking/"/>
    
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/tags/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/tags/project-reactor/"/>
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/tags/optimistic-locking/"/>
    
  </entry>
  
  <entry>
    <title>Pessimistic locking with Aerospike and Project Reactor</title>
    <link href="https://www.oxymorus.com/pessimistic-locking-with-reactor-and-aerospike/"/>
    <id>https://www.oxymorus.com/pessimistic-locking-with-reactor-and-aerospike/</id>
    <published>2019-10-05T20:47:51.000Z</published>
    <updated>2019-10-05T20:47:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to implement pessimistic locking with Aerospike and Project Reactor ?</p></div><a id="more"></a><div class="sect1"><h2>Introduction</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/pessimisticOfflineLock.html" target="_blank" rel="noopener">Pessimistic locking</a> is general pattern commonly used to maintain data consistency.</p></div><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://martinfowler.com/eaaCatalog/PessimisticSketch.gif" target="_blank" rel="noopener"><img src="https://martinfowler.com/eaaCatalog/PessimisticSketch.gif" alt="PessimisticSketch"></a></div></div><div class="paragraph"><p>In this post I will describe how to implement pessimistic locking with No-SQL storage, that has reactive client.</p></div><div class="sect2"><h3>Pessimistic lock interface</h3><div class="paragraph"><p>We will support following operations: <code>tryAcquire</code> and <code>release</code></p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public interface PessimisticLock {    Mono&lt;Boolean&gt; tryAcquire(String key);    Mono&lt;Boolean&gt; release(String key);}</code></pre></div></div></div><div class="sect2"><h3>Implementation</h3><div class="paragraph"><p>To implement pessimistic locking we will use special bin with no value and short expiration (to prevent hanged locks). The idea is simple:</p></div><div class="ulist"><ul><li><p>if there is a record in storage for given key, then lock is acquired by some other concurrent service</p></li><li><p>if there is no record, then lock is free and current service can acquire it</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Slf4j@RequiredArgsConsturctorpublic class DefaultPessimisticLock implements PessimisticLock {    private final IAerospikeReactorClient client;    private final RetryProperties retryProperties;    private final LockProperties lockProperties;    private final AerospikeProperties aerospikeProperties;    @Override    public Mono&lt;Boolean&gt; tryAcquire(String key) {        Key lockKey = toLockKey(key);        Bin lockBin = toLockBin(key);        return Mono.defer(() -&gt; client.put(acquirePolicy(), lockKey, lockBin).map(Objects::nonNull))                .retryWhen(Retries.aerospikeError(retryProperties))                .onErrorMap(error -&gt; {                    log.warn("Failed to acquire lock " + key, error);                    return new PessimisticLockAcquireException("Failed to acquire lock " + key, error);                });    }    @Override    public Mono&lt;Boolean&gt; release(String key) {        Key lockKey = toLockKey(key);        return client.delete(releasePolicy(), lockKey)                .map(Objects::nonNull)                .onErrorResume(error -&gt; {                    log.warn("Failed to release lock " + key, error);                    return Mono.just(Boolean.FALSE);                })                .defaultIfEmpty(Boolean.TRUE);    }    private Key toLockKey(String key) {        return new Key(aerospikeProperties.getNamespace(), aerospikeProperties.getSetName(), key);    }    private Bin toLockBin(String key) {        return new Bin(lockProperties.getBinName(), key);    }    private WritePolicy acquirePolicy() {        WritePolicy putPolicy = new WritePolicy();        putPolicy.recordExistsAction = RecordExistsAction.CREATE_ONLY;        putPolicy.expiration = lockProperties.getExpirationInSeconds();        return putPolicy;    }    private WritePolicy releasePolicy() {        WritePolicy deletePolicy = new WritePolicy();        deletePolicy.generationPolicy = GenerationPolicy.NONE;        return deletePolicy;    }}</code></pre></div></div></div><div class="sect2"><h3>Testing</h3><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@RunWith(MockitoJUnitRunner.class)public class DefaultPessimisticLockTest {    private static final String TEST_KEY = "123";    private static final AerospikeException AEROSPIKE_TIMEOUT_EXCEPTION = new AerospikeException(ResultCode.TIMEOUT, "Aerospike timeout");    private static final AerospikeException AERSOPIKE_KEY_EXISTS_EXCEPTION = new AerospikeException(ResultCode.KEY_EXISTS_ERROR, "Key exists");    @Mock    private IAerospikeReactorClient client;    @Spy    private AerospikeProperties aerospikeProperties = new AerospikeProperties();    @Spy    private RetryProperties retryProperties = new RetryProperties();    @Spy    private LockProperties lockProperties = new LockProperties();    @InjectMocks    private DefaultPessimisticLock pessimisticLock;    @Test    public void lockAcquireExceptionIsThrownIfTimeoutReachedAfterRetry() {        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(1001))                .expectError(PessimisticLockAcquireException.class)                .verify();    }    @Test    public void lockIsAcquiredAfterRetryWithExponentialBackOff() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(50))                .thenAwait(Duration.ofMillis(100))                .thenAwait(Duration.ofMillis(200))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockAcquireExceptionIsThrownIfKeyExistsError() {        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(1001))                .expectError(PessimisticLockAcquireException.class)                .verify();    }    @Test    public void lockIsAcquiredIfKeyBecomesAvailable() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(50))                .thenAwait(Duration.ofMillis(100))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsAcquiredSuccessfully() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsTreatedAsReleasedIfDoesNotExist() {        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.empty());        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsNotReleasedIfExceptionDuringRelease() {        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION));        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.FALSE)                .expectComplete()                .verify();    }    @Test    public void lockIsReleasedSuccessfully() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.just(testKey));        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }}</code></pre></div></div></div><div class="sect2"><h3>Using with Reactor</h3><div class="paragraph"><p>We need to emulate <code>try-finally</code> semantic with Reactor operators. The code below achieves that goal:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Overridepublic &lt;T, R&gt; Mono&lt;R&gt; executeWithLock(String key, T data, OperationExecutor&lt;T, R&gt; operationExecutor) {    return pessimisticLockOperations.tryAcquire(key)            .flatMap(lockAcquired -&gt; operationExecutor.execute(data)                    .flatMap(operationResult -&gt; pessimisticLock.release(key)                            .map(Functions.constant(operationResult)))                    .onErrorResume(throwable -&gt; pessimisticLock.release(key)                            .map(Functions.constant(operationResult)))            );}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Aerospike doesn&#8217;t have built-in mechanism for pessimistic locking. So to achieve required semantic one would need to implement locking directly.</p></div><div class="paragraph"><p>Another trick in the puzzle is <code>try-finally</code> semantic with Reactor.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to implement pessimistic locking with Aerospike and Project Reactor ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/categories/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/"/>
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/pessimistic-locking/"/>
    
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/tags/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/tags/project-reactor/"/>
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/tags/pessimistic-locking/"/>
    
  </entry>
  
  <entry>
    <title>Java concurrency tools</title>
    <link href="https://www.oxymorus.com/concurrent-sum-of-numbers/"/>
    <id>https://www.oxymorus.com/concurrent-sum-of-numbers/</id>
    <published>2019-09-27T12:07:41.000Z</published>
    <updated>2019-09-27T12:07:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>In the post I will give practical comparison of using different Java classes for implementing the same toy problem: finding sum of integers in given range.</p></div><a id="more"></a><div class="sect1"><h2>Toy problem</h2><div class="sectionbody"><div class="paragraph"><p>Suppose we want to calculate the sum of numbers in some closed range <em>[start, end]</em>. To make the task interesting, let&#8217;s do it concurrently using <em>N</em> threads.</p></div></div></div><div class="sect1"><h2>Divide and conquer</h2><div class="sectionbody"><div class="paragraph"><p>From general point of view, the described problem suits very well <em><a href="https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm" target="_blank" rel="noopener">divide and conquer</a></em> paradigm. So, applied to <em>sum finding problem</em>, general plan can look as follows:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Divide the range into sub-ranges</p></li><li><p>Delegate the job of finding sum of sub-ranges to individual threads in the pool</p></li><li><p>Aggregate sub-ranges sums by collecting results from individual threads</p></li></ol></div></div></div><div class="sect1"><h2>Implementation alternatives</h2><div class="sectionbody"><div class="paragraph"><p>The approach described above can be implemented using different tools:</p></div><div class="ulist"><ul><li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runnable.html" target="_blank" rel="noopener">Runnable</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html" target="_blank" rel="noopener">Thread</a></p></li><li><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a></p></li><li><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a></p></li><li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/stream/BaseStream.html#parallel--" target="_blank" rel="noopener">Stream.parallel</a> method</p></li></ul></div><div class="paragraph"><p>Since I&#8217;m doing this as an exercise and just to have fun, I will do an implementation for each alternative. So, let&#8217;s start.</p></div><div class="sect2"><h3>ForkJoinPool and Stream.parallel</h3><div class="paragraph"><p>For our toy problem - the resulting code is pretty concise and declarative (except part of creating <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a>).</p></div><div class="paragraph"><p><em>Note:</em> <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> is created manually in order to explicitly control the number of threads used. Probably, most often you would use <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html#commonPool--" target="_blank" rel="noopener">common pool</a>, that is created and managed by JVM implicitly.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Scanner;import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        ForkJoinPool forkJoinPool = new ForkJoinPool(numberOfThreads);        try {            return forkJoinPool.submit(() -&gt;                    IntStream.rangeClosed(rangeStart, rangeEnd)                            .parallel()                            .sum()            ).get();        } catch (InterruptedException | ExecutionException e) {            throw new RuntimeException(e);        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div><div class="sect2"><h3>ExecutorService and CompletableFuture</h3><div class="paragraph"><p>Starting from Java 8, we have pretty powerful and general tool in our toolbox - <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a>. It allows to perform async operations in much easier way then before. And overall, code becomes more declarative and composable (though cumbersome sometimes).</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.List;import java.util.Scanner;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.stream.Collectors;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);        int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);        ExecutorService executorPool = Executors.newFixedThreadPool(numberOfSubRanges);        List&lt;CompletableFuture&lt;Integer&gt;&gt; subRanges = IntStream.range(0, numberOfSubRanges)                .mapToObj(subRangeIndex -&gt; {                    int lower = rangeStart + (subRangeIndex * numbersPerSubRange);                    int upper = (subRangeIndex == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;                    return CompletableFuture.supplyAsync(() -&gt; IntStream.rangeClosed(lower, upper).sum(), executorPool);                })                .collect(Collectors.toList());        return CompletableFuture.allOf(subRanges.toArray(new CompletableFuture[0]))                .thenApply(v -&gt; {                            Integer total = subRanges.stream()                                    .map(CompletableFuture::join)                                    .reduce(0, Integer::sum);                            executorPool.shutdownNow();                            return total;                        }                ).join();    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div><div class="paragraph"><p>As we can see, we have to manage sub-ranges explicitly. In case of our toy problem - it&#8217;s overkill, but in more complex situations, this is not so big price for async and composable execution.</p></div></div><div class="sect2"><h3>ExecutorService and Future</h3><div class="paragraph"><p>Combination of <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a> is pretty powerful tool also. Although, it has the drawbacks, that led to introducing <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a>: explicit blocking and problems to compose multiple futures in declarative way.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.ArrayList;import java.util.List;import java.util.Scanner;import java.util.concurrent.Callable;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        int totalSum = 0;        try {            int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);            int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);            List&lt;Callable&lt;Integer&gt;&gt; subRanges = new ArrayList&lt;&gt;();            for (int subRangeIndex = 0; subRangeIndex &lt; numberOfSubRanges; subRangeIndex++) {                int lower = rangeStart + (subRangeIndex * numbersPerSubRange);                int upper = (subRangeIndex == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;                subRanges.add(() -&gt; IntStream.rangeClosed(lower, upper).sum());            }            ExecutorService executorPool = Executors.newFixedThreadPool(numberOfSubRanges);            List&lt;Future&lt;Integer&gt;&gt; resultFromParts = executorPool.invokeAll(subRanges, 10, TimeUnit.SECONDS);            executorPool.shutdown();            for (Future&lt;Integer&gt; result : resultFromParts) {                totalSum += result.get();            }        } catch (Exception ex) {            throw new RuntimeException(ex);        }        return totalSum;    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div><div class="sect2"><h3>Runnable and Thread</h3><div class="paragraph"><p>These are most basic tools, that could be used. The main advantage - they are available from very first version of Java.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Scanner;public class DivideAndConquerSum {    private static class Sum implements Runnable {        private final int lower;        private final int upper;        int sum;        Sum(int lower, int upper) {            this.lower = lower;            this.upper = upper;        }        @Override        public void run() {            for (int number = lower; number &lt;= upper; number++) {                sum += number;            }        }    }    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) throws InterruptedException {        int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);        int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);        Sum[] sums = new Sum[numberOfSubRanges];        Thread[] pool = new Thread[numberOfSubRanges];        for (int index = 0; index &lt; numberOfSubRanges; index++) {            int lower = rangeStart + (index * numbersPerSubRange);            int upper = (index == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;            Sum task = new Sum(lower, upper);            sums[index] = task;            Thread thread = new Thread(task);            pool[index] = thread;            thread.start();        }        for (Thread thread : pool) {            thread.join();        }        int totalSum = 0;        for (Sum sum : sums) {            totalSum += sum.sum;        }        return totalSum;    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>If you would encounter a task to find sum of integers in the given range, you should choose <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/stream/BaseStream.html#parallel--" target="_blank" rel="noopener">Stream.parallel</a> for several basic reasons:</p></div><div class="ulist"><ul><li><p>the produced code is most concise</p></li><li><p>the produced code relies on standard Java library, that is heavily tested and widely used</p></li></ul></div><div class="paragraph"><p>However, for situations a bit more complex then described toy problem, other approaches become relevant:</p></div><div class="ulist"><ul><li><p>with Java prior to Java 5 - you would use <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runnable.html" target="_blank" rel="noopener">Runnable</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html" target="_blank" rel="noopener">Thread</a></p></li><li><p>with Java 5/6/7 - consider using <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a></p></li><li><p>with Java 8 - consider using <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a></p></li></ul></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the post I will give practical comparison of using different Java classes for implementing the same toy problem: finding sum of integers in given range.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="java.util.concurrent" scheme="https://www.oxymorus.com/categories/java-util-concurrent/"/>
    
      <category term="CompletableFuture" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/"/>
    
      <category term="Future" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/"/>
    
      <category term="Thread" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/"/>
    
      <category term="Runnable" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/runnable/"/>
    
      <category term="ForkJoinPool" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/runnable/forkjoinpool/"/>
    
    
      <category term="java.util.concurrent" scheme="https://www.oxymorus.com/tags/java-util-concurrent/"/>
    
      <category term="CompletableFuture" scheme="https://www.oxymorus.com/tags/completablefuture/"/>
    
      <category term="Future" scheme="https://www.oxymorus.com/tags/future/"/>
    
      <category term="Thread" scheme="https://www.oxymorus.com/tags/thread/"/>
    
      <category term="Runnable" scheme="https://www.oxymorus.com/tags/runnable/"/>
    
      <category term="ForkJoinPool" scheme="https://www.oxymorus.com/tags/forkjoinpool/"/>
    
  </entry>
  
  <entry>
    <title>Back-pressure patterns in practice</title>
    <link href="https://www.oxymorus.com/backpressure/"/>
    <id>https://www.oxymorus.com/backpressure/</id>
    <published>2019-06-19T10:58:44.000Z</published>
    <updated>2019-06-19T10:58:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>Back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load.</p></div><a id="more"></a><div class="sect1"><h2>Back-Pressure</h2><div class="sectionbody"><div class="paragraph"><p>This is how it&#8217;s defined in <a href="https://www.reactivemanifesto.org/glossary#Back-Pressure" target="_blank" rel="noopener">Reactive Manifesto</a>:</p></div><div class="quoteblock"><blockquote><div class="paragraph"><p><strong>Back-Pressure</strong></p></div><div class="paragraph"><p>When one component is struggling to keep-up, the system as a whole needs to respond in a sensible way. It is unacceptable for the component under stress to fail catastrophically or to drop messages in an uncontrolled fashion. Since it can’t cope and it can’t fail it should communicate the fact that it is under stress to upstream components and so get them to reduce the load. This back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load, and will provide information that may allow the system itself to apply other resources to help distribute the load.</p></div></blockquote></div><div class="paragraph"><p>Let&#8217;s illustrate the context, that requires to apply back-pressure.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/backpressure.png"><img src="/images/backpressure.png" alt="backpressure"></a></div></div></div></div><div class="paragraph"><p>So, essentially the problem here is the mismatch in throughput between services.</p></div></div></div><div class="sect1"><h2>Strategies to deal with throughput mismatch</h2><div class="sectionbody"><div class="paragraph"><p>There are several strategies to deal with throughput mismatch:</p></div><div class="ulist"><ul><li><p><em>Auto-scale</em> service, that is under pressure</p></li><li><p><em>Drop down (or sample)</em> incoming requests, once service under pressure is saturated</p></li><li><p><em>Buffer</em> requests</p></li><li><p><em>Control</em> the request producer</p></li></ul></div><div class="sect2"><h3>Auto-scaling</h3><div class="paragraph"><p>Probably, auto-scaling is the easiest way to deal with the problem. E.g. in the example above the solution would be to scale the <strong>service B</strong> up - this definitely will resolve throughput deficit. In some cases this will be just enough, but in other - auto-scaling might lead to propagating the problem to the next service (e.g. <strong>service C</strong>). Also, if you are in severe cost/hardware deficit, scaling up is simply not feasible.</p></div></div><div class="sect2"><h3>Dropping down or sampling</h3><div class="paragraph"><p>Only some fraction of incoming requests is processed, other are simply ignored. E.g. in the example above to solve the problem it would be enough for <strong>service B</strong> to just skip processing every 3rd request. However, most often it&#8217;s not applicable in practice</p></div></div><div class="sect2"><h3>Buffering requests</h3><div class="paragraph"><p>Probably, applying buffer is the most intuitive thing to do. E.g. in the example above this approach can be implemented by introducing messaging queue between <strong>service A and B</strong> or, alternatively, storing incoming request to the database. This, in essence, allows <strong>service B</strong> to pull requests from buffer, when it&#8217;s ready to process them. However, beside the complication in infrastructure it&#8217;s not always possible, since not all requests might be processed asynchronously.</p></div></div><div class="sect2"><h3>Controlling the request producer</h3><div class="paragraph"><p>Controlling the request producer is, actually, defined as"back-pressure" by Reactive Manifesto. In the example above it means, that <strong>service B</strong> should be able to slow down/speed up <strong>service A</strong>. So, <strong>service A</strong> should not <em>push</em> requests to <strong>service B</strong>, instead <strong>service B</strong> should <em>pull</em> desired number of requests from <strong>service A</strong>. However, controlling producer speed is not always an option (imaging telling your user to slow down). Also, back-pressure mechanism introduces complexity in the system, so should be decided carefully.</p></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Whenever there is a mismatch in throughput between services there might be the opportunity to apply back-pressure pattern.</p></div><div class="paragraph"><p>What strategy should be applied really depends on the constraints and requirements at hand.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Reactive" scheme="https://www.oxymorus.com/categories/reactive/"/>
    
      <category term="Back-Pressure" scheme="https://www.oxymorus.com/categories/reactive/back-pressure/"/>
    
    
      <category term="back-pressure" scheme="https://www.oxymorus.com/tags/back-pressure/"/>
    
  </entry>
  
  <entry>
    <title>Trick Of The Day: Cloning all Github repositories</title>
    <link href="https://www.oxymorus.com/clone-all-github-repos/"/>
    <id>https://www.oxymorus.com/clone-all-github-repos/</id>
    <published>2019-06-17T22:52:55.000Z</published>
    <updated>2019-06-17T22:52:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to clone all github repositories for specific organization?</p></div><a id="more"></a><div class="sect1"><h2>Situation</h2><div class="sectionbody"><div class="paragraph"><p>You need to clone all repos for your organization on github/on-premise github. Since there might be plenty of repos you don&#8217;t want to repeat yourself and prefer automate this process.</p></div></div></div><div class="sect1"><h2>Solution</h2><div class="sectionbody"><div class="ulist"><ul><li><p>Create an API token by going to Account Settings &#8594; Applications</p></li><li><p>Clone repos:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ GITHUB_BASE_URL={api.github.com|yourcompanygithub}; CONTEXT={users|orgs}; NAME={username|orgname}; ACCESS_TOKEN={yourtoken}$ curl "https://$GITHUB_BASE_URL/api/v3/$CONTEXT/$NAME/repos?page=1&amp;per_page=100&amp;access_token=$ACCESS_TOKEN" \     | jq '.[] | .clone_url' \     | xargs -L1 git clone</code></pre></div></div><div class="paragraph"><p><strong>Notes:</strong></p></div><div class="olist arabic"><ol class="arabic"><li><p><em>CONTEXT=users</em> and <em>NAME=yourusername</em> will clone all your repositories.</p></li><li><p><em>CONTEXT=orgs</em> and <em>NAME=yourorgname</em> will clone all repositories of your organization.</p></li><li><p>The solutions assumes you have <a href="https://stedolan.github.io/jq/manual/" target="_blank" rel="noopener">jq</a> installed. <em>If you haven&#8217;t, it&#8217;s time to do it.</em></p></li></ol></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to clone all github repositories for specific organization?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Github" scheme="https://www.oxymorus.com/categories/github/"/>
    
      <category term="clone" scheme="https://www.oxymorus.com/categories/github/clone/"/>
    
      <category term="jq" scheme="https://www.oxymorus.com/categories/github/clone/jq/"/>
    
    
      <category term="Github" scheme="https://www.oxymorus.com/tags/github/"/>
    
      <category term="clone" scheme="https://www.oxymorus.com/tags/clone/"/>
    
      <category term="jq" scheme="https://www.oxymorus.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Trick Of The Day: Copy DB dump from one Docker container to another</title>
    <link href="https://www.oxymorus.com/docker-mysql-dump/"/>
    <id>https://www.oxymorus.com/docker-mysql-dump/</id>
    <published>2019-04-23T22:52:55.000Z</published>
    <updated>2019-04-23T22:52:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to copy MySQL dump from one Docker container to another ?</p></div><a id="more"></a><div class="sect1"><h2>Situation</h2><div class="sectionbody"><div class="paragraph"><p>You need to create DB dump in one Docker container and apply it in another Docker container.</p></div></div></div><div class="sect1"><h2>Application</h2><div class="sectionbody"><div class="paragraph"><p>Crate DB dump on staging env and apply it on local env to experiment with existing database.</p></div></div></div><div class="sect1"><h2>Solution</h2><div class="sectionbody"><div class="ulist"><ul><li><p>Connect to first container:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ docker exec -ti mysql-staging /bin/bash</code></pre></div></div><div class="ulist"><ul><li><p>Create DB dump:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ mysqldump -u user -p --databases db &gt; /tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Copy dump to localhost:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh"># general syntax:# docker cp CONTAINER:SRC_PATH DEST_PATH$ docker cp mysql:/tmp/db.sql /tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Copy dump to second container:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh"># general syntax:# docker cp DEST_PATH CONTAINER:SRC_PATH$ docker cp /tmp/db.sql mysql:/tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Apply DB dump:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ docker exec -ti mysql /bin/bash$ mysql -u user -p-- Run the backup script to recreate the databasemysql&gt; drop database if exists db;mysql&gt; source /tmp/db.sql</code></pre></div></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to copy MySQL dump from one Docker container to another ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://www.oxymorus.com/categories/docker/"/>
    
      <category term="MySQL" scheme="https://www.oxymorus.com/categories/docker/mysql/"/>
    
      <category term="dump" scheme="https://www.oxymorus.com/categories/docker/mysql/dump/"/>
    
    
      <category term="Docker" scheme="https://www.oxymorus.com/tags/docker/"/>
    
      <category term="MySQL" scheme="https://www.oxymorus.com/tags/mysql/"/>
    
  </entry>
  
</feed>
