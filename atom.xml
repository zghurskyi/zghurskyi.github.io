<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yet Another Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.oxymorus.com/"/>
  <updated>2019-10-16T16:53:41.000Z</updated>
  <id>https://www.oxymorus.com/</id>
  
  <author>
    <name>Oleksii Zghurskyi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache Camel: Masking sensitive information</title>
    <link href="https://www.oxymorus.com/camel-masking-sensitive-information/"/>
    <id>https://www.oxymorus.com/camel-masking-sensitive-information/</id>
    <published>2019-10-16T16:53:41.000Z</published>
    <updated>2019-10-16T16:53:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>It&#8217;s pretty common to log incoming requests or message bodies via <a href="https://camel.apache.org/components/latest/log-component.html" target="_blank" rel="noopener">Log component</a>. Usually, logging incoming data is harmless. However, sometime you may accidentally include secure/sensitive information. What to do in this case ?</p></div><a id="more"></a><div class="sect1"><h2>Masking sensitive information in Apache Camel</h2><div class="sectionbody"><div class="paragraph"><p>Apache Camel supports security masking for logging, when you set <code>logMask</code> flag to <code>true</code>. This feature is available starting from <a href="https://camel.apache.org/manual/latest/log-eip.html#_masking_sensitive_information_like_password" target="_blank" rel="noopener">Camel 2.19</a></p></div><div class="paragraph"><p>You can enable masking at <code>CamelContext</code> level and, also, at route level:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">// enable at CamelContext levelcamelContext.setLogMask(true);// enable at route levelfrom("direct:start").logMask()    .log("Processing ${id}")    .to("bean:foo");</code></pre></div></div><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content">By default, <a href="https://static.javadoc.io/org.apache.camel/camel-core/2.24.2/org/apache/camel/processor/DefaultMaskingFormatter.html" target="_blank" rel="noopener">DefaultMaskingFormatter</a> is used: this formatter searches specified keywords in the source and replaces its value with mask string (<code>xxxxx</code>). It&#8217;s important to note, that <code>DefaultMaskingFormatter</code> masks only <code>"passphrase"</code>, <code>"password"</code> and <code>"secretKey"</code> keywords. So, if you need to mask other keywords, you&#8217;ll have to make custom configuration.</td></tr></table></div></div></div><div class="sect1"><h2>Configuring custom masking formatter</h2><div class="sectionbody"><div class="paragraph"><p>If you want to use a custom masking formatter, you should put it into Camel service registry with the name <code>CamelCustomLogMask</code>. Note that your formatter must implement <a href="https://static.javadoc.io/org.apache.camel/camel-core/2.24.2/org/apache/camel/spi/MaskingFormatter.html" target="_blank" rel="noopener">MaskingFormatter</a>.</p></div><div class="paragraph"><p>However, if you&#8217;re using <a href="https://camel.apache.org/components/latest/spring-boot.html" target="_blank" rel="noopener">Spring Boot auto-configuration for Apache Camel</a>, it&#8217;s actually pretty easy to just configure <code>DefaultMaskingFormatter</code> with your custom masking keywords.</p></div><div class="paragraph"><p>For example, let&#8217;s enable masking of <code>value</code> keyword:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Beanpublic Registry maskingRegistry() {    MaskingFormatter valueMaskingFormatter =        new DefaultMaskingFormatter(                Collections.singleton("value"), <i class="conum" data-value="1"></i><b>(1)</b>                true,                           <i class="conum" data-value="2"></i><b>(2)</b>                true,                           <i class="conum" data-value="3"></i><b>(3)</b>                true                            <i class="conum" data-value="4"></i><b>(4)</b>        );    SimpleRegistry simpleRegistry = new SimpleRegistry();    simpleRegistry.put(Constants.CUSTOM_LOG_MASK_REF, valueMaskingFormatter);    return simpleRegistry;}</code></pre></div></div><div class="colist arabic"><table><tr><td><i class="conum" data-value="1"></i><b>1</b></td><td>set of <code>keywords</code>, that should be masked</td></tr><tr><td><i class="conum" data-value="2"></i><b>2</b></td><td>flag to turn on/off masking of key-value (e.g. in <a href="https://camel.apache.org/components/latest/properties-component.html" target="_blank" rel="noopener">properties component</a>)</td></tr><tr><td><i class="conum" data-value="3"></i><b>3</b></td><td>flag to turn on/off masking XML element</td></tr><tr><td><i class="conum" data-value="4"></i><b>4</b></td><td>flag to turn on/off masking JSON field</td></tr></table></div><div class="paragraph"><p>Also, to turn on <code>logMask</code> globally, you need to add following config to your <code>application.yml</code>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">camel:  springboot:    logMask: true</code></pre></div></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;It&amp;#8217;s pretty common to log incoming requests or message bodies via &lt;a href=&quot;https://camel.apache.org/components/latest/log-component.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Log component&lt;/a&gt;. Usually, logging incoming data is harmless. However, sometime you may accidentally include secure/sensitive information. What to do in this case ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Apache Camel" scheme="https://www.oxymorus.com/categories/apache-camel/"/>
    
      <category term="CamelCustomLogMask" scheme="https://www.oxymorus.com/categories/apache-camel/camelcustomlogmask/"/>
    
    
      <category term="Apache Camel" scheme="https://www.oxymorus.com/tags/apache-camel/"/>
    
      <category term="CamelCustomLogMask" scheme="https://www.oxymorus.com/tags/camelcustomlogmask/"/>
    
  </entry>
  
  <entry>
    <title>Optimistic locking with Aerospike and Project Reactor</title>
    <link href="https://www.oxymorus.com/optimistic-locking-with-reactor-and-aerospike/"/>
    <id>https://www.oxymorus.com/optimistic-locking-with-reactor-and-aerospike/</id>
    <published>2019-10-06T19:47:51.000Z</published>
    <updated>2019-10-06T19:47:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to implement optimistic locking with Aerospike and Project Reactor ?</p></div><a id="more"></a><div class="sect1"><h2>Introduction</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/optimisticOfflineLock.html" target="_blank" rel="noopener">Optimistic locking</a> is general pattern commonly used to maintain data consistency.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://martinfowler.com/eaaCatalog/OptimisticSketch.gif" target="_blank" rel="noopener"><img src="https://martinfowler.com/eaaCatalog/OptimisticSketch.gif" alt="OptimisticSketch"></a></div></div></div></div><div class="paragraph"><p>In this post I will describe how to implement optimistic locking with No-SQL storage, that has reactive client.</p></div><div class="sect2"><h3>Aerospike <code>generation</code> meta-data</h3><div class="paragraph"><p>In traditional RDBMS to implement optimistic locking one would have to introduce additional <code>version</code> or <code>timestamp</code> column.</p></div><div class="paragraph"><p>In case of Aerospike, required data is available by default: each record has <code>generation</code> meta-data. So, in order to fail, when record is updated/deleted concurrently, one would need only enable <code>GenerationPolicy.EXPECT_GEN_EQUAL</code>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ClientPolicy clientPolicy = new ClientPolicy();clientPolicy.writePolicyDefault.generationPolicy = GenerationPolicy.EXPECT_GEN_EQUAL;</code></pre></div></div><div class="paragraph"><p>Having above config in place ensures that update/delete will be executed successfully, if expected generation is equal to server generation, otherwise, update/delete will fail.</p></div></div><div class="sect2"><h3>Reactor <code>retryWhen</code> operation</h3><div class="paragraph"><p><a href="https://projectreactor.io/" target="_blank" rel="noopener">Project Reactor</a> is a fourth-generation Reactive library for building non-blocking applications on the JVM based on the <a href="https://github.com/reactive-streams/reactive-streams-jvm" target="_blank" rel="noopener">Reactive Streams Specification</a>.</p></div><div class="paragraph"><p>In the context of our goal, we will use <a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html#retryWhen-java.util.function.Function-" target="_blank" rel="noopener">retryWhen</a> operation:</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/doc-files/marbles/retryWhenForMono.svg" target="_blank" rel="noopener"><img src="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/doc-files/marbles/retryWhenForMono.svg" alt="retryWhenForMono"></a></div></div></div></div></div><div class="sect2"><h3>Implementation</h3><div class="paragraph"><p>Now let&#8217;s put everything together and write method that performs <code>createOrUpdate</code> operation on <code>Data</code> instance:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public Mono&lt;Data&gt; createOrUpdate(Data data) {    return Mono.defer(() -&gt; doCreateOrUpdate(data))            .retryWhen(Retries.optimisticLockException(retryProperties)                    .doOnRetry(context -&gt; log.warn("Retrying optimistic failure for data", data, context.exception()))            );}private Mono&lt;Data&gt; doCreateOrUpdate(Data data) {    return repository.findDataByKey(data.getKey())            .map(existingData -&gt; data.withGeneration(existingData.getGeneration()))            .flatMap(existingData -&gt; repository.createOrUpdate(existingData).map(Functions.constant(existingData)));}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Implementing optimistic locking with Aerospike and Reactor is pretty straight-forward. Since all tools are already in place, all that needs to be done - put everything together.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to implement optimistic locking with Aerospike and Project Reactor ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/categories/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/"/>
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/optimistic-locking/"/>
    
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/tags/optimistic-locking/"/>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/tags/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/tags/project-reactor/"/>
    
  </entry>
  
  <entry>
    <title>Pessimistic locking with Aerospike and Project Reactor</title>
    <link href="https://www.oxymorus.com/pessimistic-locking-with-reactor-and-aerospike/"/>
    <id>https://www.oxymorus.com/pessimistic-locking-with-reactor-and-aerospike/</id>
    <published>2019-10-05T20:47:51.000Z</published>
    <updated>2019-10-05T20:47:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to implement pessimistic locking with Aerospike and Project Reactor ?</p></div><a id="more"></a><div class="sect1"><h2>Introduction</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/pessimisticOfflineLock.html" target="_blank" rel="noopener">Pessimistic locking</a> is general pattern commonly used to maintain data consistency.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="https://martinfowler.com/eaaCatalog/PessimisticSketch.gif" target="_blank" rel="noopener"><img src="https://martinfowler.com/eaaCatalog/PessimisticSketch.gif" alt="PessimisticSketch"></a></div></div></div></div><div class="paragraph"><p>In this post I will describe how to implement pessimistic locking with No-SQL storage, that has reactive client.</p></div><div class="sect2"><h3>Pessimistic lock interface</h3><div class="paragraph"><p>We will support following operations: <code>tryAcquire</code> and <code>release</code></p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public interface PessimisticLock {    Mono&lt;Boolean&gt; tryAcquire(String key);    Mono&lt;Boolean&gt; release(String key);}</code></pre></div></div></div><div class="sect2"><h3>Implementation</h3><div class="paragraph"><p>To implement pessimistic locking we will use special bin with no value and short expiration (to prevent hanged locks). The idea is simple:</p></div><div class="ulist"><ul><li><p>if there is a record in storage for given key, then lock is acquired by some other concurrent service</p></li><li><p>if there is no record, then lock is free and current service can acquire it</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Slf4j@RequiredArgsConsturctorpublic class DefaultPessimisticLock implements PessimisticLock {    private final IAerospikeReactorClient client;    private final RetryProperties retryProperties;    private final LockProperties lockProperties;    private final AerospikeProperties aerospikeProperties;    @Override    public Mono&lt;Boolean&gt; tryAcquire(String key) {        Key lockKey = toLockKey(key);        Bin lockBin = toLockBin(key);        return Mono.defer(() -&gt; client.put(acquirePolicy(), lockKey, lockBin).map(Objects::nonNull))                .retryWhen(Retries.aerospikeError(retryProperties))                .onErrorMap(error -&gt; {                    log.warn("Failed to acquire lock " + key, error);                    return new PessimisticLockAcquireException("Failed to acquire lock " + key, error);                });    }    @Override    public Mono&lt;Boolean&gt; release(String key) {        Key lockKey = toLockKey(key);        return client.delete(releasePolicy(), lockKey)                .map(Objects::nonNull)                .onErrorResume(error -&gt; {                    log.warn("Failed to release lock " + key, error);                    return Mono.just(Boolean.FALSE);                })                .defaultIfEmpty(Boolean.TRUE);    }    private Key toLockKey(String key) {        return new Key(aerospikeProperties.getNamespace(), aerospikeProperties.getSetName(), key);    }    private Bin toLockBin(String key) {        return new Bin(lockProperties.getBinName(), key);    }    private WritePolicy acquirePolicy() {        WritePolicy putPolicy = new WritePolicy();        putPolicy.recordExistsAction = RecordExistsAction.CREATE_ONLY;        putPolicy.expiration = lockProperties.getExpirationInSeconds();        return putPolicy;    }    private WritePolicy releasePolicy() {        WritePolicy deletePolicy = new WritePolicy();        deletePolicy.generationPolicy = GenerationPolicy.NONE;        return deletePolicy;    }}</code></pre></div></div></div><div class="sect2"><h3>Testing</h3><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@RunWith(MockitoJUnitRunner.class)public class DefaultPessimisticLockTest {    private static final String TEST_KEY = "123";    private static final AerospikeException AEROSPIKE_TIMEOUT_EXCEPTION = new AerospikeException(ResultCode.TIMEOUT, "Aerospike timeout");    private static final AerospikeException AERSOPIKE_KEY_EXISTS_EXCEPTION = new AerospikeException(ResultCode.KEY_EXISTS_ERROR, "Key exists");    @Mock    private IAerospikeReactorClient client;    @Spy    private AerospikeProperties aerospikeProperties = new AerospikeProperties();    @Spy    private RetryProperties retryProperties = new RetryProperties();    @Spy    private LockProperties lockProperties = new LockProperties();    @InjectMocks    private DefaultPessimisticLock pessimisticLock;    @Test    public void lockAcquireExceptionIsThrownIfTimeoutReachedAfterRetry() {        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(1001))                .expectError(PessimisticLockAcquireException.class)                .verify();    }    @Test    public void lockIsAcquiredAfterRetryWithExponentialBackOff() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(50))                .thenAwait(Duration.ofMillis(100))                .thenAwait(Duration.ofMillis(200))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockAcquireExceptionIsThrownIfKeyExistsError() {        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(1001))                .expectError(PessimisticLockAcquireException.class)                .verify();    }    @Test    public void lockIsAcquiredIfKeyBecomesAvailable() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.error(AERSOPIKE_KEY_EXISTS_EXCEPTION))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .thenAwait(Duration.ofMillis(50))                .thenAwait(Duration.ofMillis(100))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsAcquiredSuccessfully() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.put(Mockito.any(WritePolicy.class), Mockito.any(Key.class), Mockito.any(Bin.class)))                .thenReturn(Mono.just(testKey));        StepVerifier.withVirtualTime(() -&gt; pessimisticLock.tryAcquire(TEST_KEY))                .expectSubscription()                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsTreatedAsReleasedIfDoesNotExist() {        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.empty());        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }    @Test    public void lockIsNotReleasedIfExceptionDuringRelease() {        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.error(AEROSPIKE_TIMEOUT_EXCEPTION));        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.FALSE)                .expectComplete()                .verify();    }    @Test    public void lockIsReleasedSuccessfully() {        Key testKey = new Key(aerospikeProperties.getNamespace(), transactionProperties.getSetName(), TEST_KEY);        Mockito.when(client.delete(Mockito.any(WritePolicy.class), Mockito.any(Key.class)))                .thenReturn(Mono.just(testKey));        StepVerifier.create(pessimisticLock.release(TEST_KEY))                .expectNext(Boolean.TRUE)                .expectComplete()                .verify();    }}</code></pre></div></div></div><div class="sect2"><h3>Using with Reactor</h3><div class="paragraph"><p>We need to emulate <code>try-finally</code> semantic with Reactor operators. The code below achieves that goal:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Overridepublic &lt;T, R&gt; Mono&lt;R&gt; executeWithLock(String key, T data, OperationExecutor&lt;T, R&gt; operationExecutor) {    return pessimisticLockOperations.tryAcquire(key)            .flatMap(lockAcquired -&gt; operationExecutor.execute(data)                    .flatMap(operationResult -&gt; pessimisticLock.release(key)                            .map(Functions.constant(operationResult)))                    .onErrorResume(throwable -&gt; pessimisticLock.release(key)                            .map(Functions.constant(operationResult)))            );}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Aerospike doesn&#8217;t have built-in mechanism for pessimistic locking. So to achieve required semantic one would need to implement locking directly.</p></div><div class="paragraph"><p>Another trick in the puzzle is <code>try-finally</code> semantic with Reactor.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to implement pessimistic locking with Aerospike and Project Reactor ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/categories/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/"/>
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/categories/aerospike/project-reactor/pessimistic-locking/"/>
    
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/tags/pessimistic-locking/"/>
    
      <category term="Aerospike" scheme="https://www.oxymorus.com/tags/aerospike/"/>
    
      <category term="Project Reactor" scheme="https://www.oxymorus.com/tags/project-reactor/"/>
    
  </entry>
  
  <entry>
    <title>Java concurrency tools</title>
    <link href="https://www.oxymorus.com/concurrent-sum-of-numbers/"/>
    <id>https://www.oxymorus.com/concurrent-sum-of-numbers/</id>
    <published>2019-09-27T12:07:41.000Z</published>
    <updated>2019-10-07T12:07:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>In the post I will give practical comparison of using different Java classes for implementing the same toy problem: finding sum of integers in given range.</p></div><a id="more"></a><div class="sect1"><h2>Toy problem</h2><div class="sectionbody"><div class="paragraph"><p>Suppose we want to calculate the sum of numbers in some closed range <em>[start, end]</em>. To make the task interesting, let&#8217;s do it concurrently using <em>N</em> threads.</p></div></div></div><div class="sect1"><h2>Divide and conquer</h2><div class="sectionbody"><div class="paragraph"><p>From general point of view, the described problem suits very well <em><a href="https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm" target="_blank" rel="noopener">divide and conquer</a></em> paradigm. So, applied to <em>sum finding problem</em>, general plan can look as follows:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Divide the range into sub-ranges</p></li><li><p>Delegate the job of finding sum of sub-ranges to individual threads in the pool</p></li><li><p>Aggregate sub-ranges sums by collecting results from individual threads</p></li></ol></div></div></div><div class="sect1"><h2>Implementation alternatives</h2><div class="sectionbody"><div class="paragraph"><p>The approach described above can be implemented using different tools:</p></div><div class="ulist"><ul><li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runnable.html" target="_blank" rel="noopener">Runnable</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html" target="_blank" rel="noopener">Thread</a></p></li><li><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a></p></li><li><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a></p></li><li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/stream/BaseStream.html#parallel--" target="_blank" rel="noopener">Stream.parallel</a> method</p></li></ul></div><div class="paragraph"><p>Since I&#8217;m doing this as an exercise and just to have fun, I will do an implementation for each alternative. So, let&#8217;s start.</p></div><div class="sect2"><h3>ForkJoinPool and Stream.parallel</h3><div class="paragraph"><p>For our toy problem - the resulting code is pretty concise and declarative (except part of creating <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a>).</p></div><div class="paragraph"><p><em>Note:</em> <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> is created manually in order to explicitly control the number of threads used. Probably, most often you would use <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html#commonPool--" target="_blank" rel="noopener">common pool</a>, that is created and managed by JVM implicitly.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Scanner;import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        ForkJoinPool forkJoinPool = new ForkJoinPool(numberOfThreads);        try {            return forkJoinPool.submit(() -&gt;                    IntStream.rangeClosed(rangeStart, rangeEnd)                            .parallel()                            .sum()            ).get();        } catch (InterruptedException | ExecutionException e) {            throw new RuntimeException(e);        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div><div class="sect2"><h3>ExecutorService and CompletableFuture</h3><div class="paragraph"><p>Starting from Java 8, we have pretty powerful and general tool in our toolbox - <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a>. It allows to perform async operations in much easier way then before. And overall, code becomes more declarative and composable (though cumbersome sometimes).</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.List;import java.util.Scanner;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.stream.Collectors;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);        int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);        ExecutorService executorPool = Executors.newFixedThreadPool(numberOfSubRanges);        List&lt;CompletableFuture&lt;Integer&gt;&gt; subRanges = IntStream.range(0, numberOfSubRanges)                .mapToObj(subRangeIndex -&gt; {                    int lower = rangeStart + (subRangeIndex * numbersPerSubRange);                    int upper = (subRangeIndex == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;                    return CompletableFuture.supplyAsync(() -&gt; IntStream.rangeClosed(lower, upper).sum(), executorPool);                })                .collect(Collectors.toList());        return CompletableFuture.allOf(subRanges.toArray(new CompletableFuture[0]))                .thenApply(v -&gt; {                            Integer total = subRanges.stream()                                    .map(CompletableFuture::join)                                    .reduce(0, Integer::sum);                            executorPool.shutdownNow();                            return total;                        }                ).join();    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div><div class="paragraph"><p>As we can see, we have to manage sub-ranges explicitly. In case of our toy problem - it&#8217;s overkill, but in more complex situations, this is not so big price for async and composable execution.</p></div></div><div class="sect2"><h3>ExecutorService and Future</h3><div class="paragraph"><p>Combination of <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a> is pretty powerful tool also. Although, it has the drawbacks, that led to introducing <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a>: explicit blocking and problems to compose multiple futures in declarative way.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.ArrayList;import java.util.List;import java.util.Scanner;import java.util.concurrent.Callable;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;import java.util.stream.IntStream;public class DivideAndConquerSum {    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) {        int totalSum = 0;        try {            int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);            int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);            List&lt;Callable&lt;Integer&gt;&gt; subRanges = new ArrayList&lt;&gt;();            for (int subRangeIndex = 0; subRangeIndex &lt; numberOfSubRanges; subRangeIndex++) {                int lower = rangeStart + (subRangeIndex * numbersPerSubRange);                int upper = (subRangeIndex == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;                subRanges.add(() -&gt; IntStream.rangeClosed(lower, upper).sum());            }            ExecutorService executorPool = Executors.newFixedThreadPool(numberOfSubRanges);            List&lt;Future&lt;Integer&gt;&gt; resultFromParts = executorPool.invokeAll(subRanges, 10, TimeUnit.SECONDS);            executorPool.shutdown();            for (Future&lt;Integer&gt; result : resultFromParts) {                totalSum += result.get();            }        } catch (Exception ex) {            throw new RuntimeException(ex);        }        return totalSum;    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div><div class="sect2"><h3>Runnable and Thread</h3><div class="paragraph"><p>These are most basic tools, that could be used. The main advantage - they are available from very first version of Java.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Scanner;public class DivideAndConquerSum {    private static class Sum implements Runnable {        private final int lower;        private final int upper;        int sum;        Sum(int lower, int upper) {            this.lower = lower;            this.upper = upper;        }        @Override        public void run() {            for (int number = lower; number &lt;= upper; number++) {                sum += number;            }        }    }    private static int sum(int rangeStart, int rangeEnd, int numberOfThreads) throws InterruptedException {        int numberOfSubRanges = Math.min(numberOfThreads, rangeEnd - rangeStart + 1);        int numbersPerSubRange = findNumbersPerSubRanges(rangeStart, rangeEnd, numberOfThreads);        Sum[] sums = new Sum[numberOfSubRanges];        Thread[] pool = new Thread[numberOfSubRanges];        for (int index = 0; index &lt; numberOfSubRanges; index++) {            int lower = rangeStart + (index * numbersPerSubRange);            int upper = (index == numberOfThreads - 1) ? rangeEnd : lower + numbersPerSubRange - 1;            Sum task = new Sum(lower, upper);            sums[index] = task;            Thread thread = new Thread(task);            pool[index] = thread;            thread.start();        }        for (Thread thread : pool) {            thread.join();        }        int totalSum = 0;        for (Sum sum : sums) {            totalSum += sum.sum;        }        return totalSum;    }    private static int findNumbersPerSubRanges(int rangeStart, int rangeEnd, int numberOfThreads) {        if (numberOfThreads &gt;= rangeEnd - rangeStart + 1) {            return 1;        } else {            return (rangeEnd - rangeStart + 1) / numberOfThreads;        }    }    public static void main(String[] args) throws InterruptedException {        try (Scanner input = new Scanner(System.in)) {            int rangeStart, rangeEnd, numberOfThreads;            do {                System.out.print("Enter the range start: ");                rangeStart = input.nextInt();                System.out.print("Enter the range end: ");                rangeEnd = input.nextInt();                System.out.print("Enter the number of threads: ");                numberOfThreads = input.nextInt();                if (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1) {                    System.out.println("Warning: range start should be less then range end. Also number of threads should not be less then 1.");                }            } while (rangeStart &gt;= rangeEnd || numberOfThreads &lt; 1);            int sum = DivideAndConquerSum.sum(rangeStart, rangeEnd, numberOfThreads);            System.out.println(String.format("Sum of numbers in the range [%s, %s] found in %s threads is %s",                    rangeStart, rangeEnd, numberOfThreads, sum));        }    }}</code></pre></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>If you would encounter a task to find sum of integers in the given range, you should choose <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html" target="_blank" rel="noopener">ForkJoinPool</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/stream/BaseStream.html#parallel--" target="_blank" rel="noopener">Stream.parallel</a> for several basic reasons:</p></div><div class="ulist"><ul><li><p>the produced code is most concise</p></li><li><p>the produced code relies on standard Java library, that is heavily tested and widely used</p></li></ul></div><div class="paragraph"><p>However, for situations a bit more complex then described toy problem, other approaches become relevant:</p></div><div class="ulist"><ul><li><p>with Java prior to Java 5 - you would use <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runnable.html" target="_blank" rel="noopener">Runnable</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html" target="_blank" rel="noopener">Thread</a></p></li><li><p>with Java 5/6/7 - consider using <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html" target="_blank" rel="noopener">ExecutorService</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Future.html" target="_blank" rel="noopener">Future</a></p></li><li><p>with Java 8 - consider using <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html" target="_blank" rel="noopener">CompletableFuture</a></p></li></ul></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;In the post I will give practical comparison of using different Java classes for implementing the same toy problem: finding sum of integers in given range.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="java.util.concurrent" scheme="https://www.oxymorus.com/categories/java-util-concurrent/"/>
    
      <category term="CompletableFuture" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/"/>
    
      <category term="Future" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/"/>
    
      <category term="Thread" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/"/>
    
      <category term="Runnable" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/runnable/"/>
    
      <category term="ForkJoinPool" scheme="https://www.oxymorus.com/categories/java-util-concurrent/completablefuture/future/thread/runnable/forkjoinpool/"/>
    
    
      <category term="java.util.concurrent" scheme="https://www.oxymorus.com/tags/java-util-concurrent/"/>
    
      <category term="CompletableFuture" scheme="https://www.oxymorus.com/tags/completablefuture/"/>
    
      <category term="Future" scheme="https://www.oxymorus.com/tags/future/"/>
    
      <category term="Thread" scheme="https://www.oxymorus.com/tags/thread/"/>
    
      <category term="Runnable" scheme="https://www.oxymorus.com/tags/runnable/"/>
    
      <category term="ForkJoinPool" scheme="https://www.oxymorus.com/tags/forkjoinpool/"/>
    
  </entry>
  
  <entry>
    <title>Monitoring Spring Boot service with Prometheus and Grafana</title>
    <link href="https://www.oxymorus.com/observability/"/>
    <id>https://www.oxymorus.com/observability/</id>
    <published>2019-09-11T22:07:41.000Z</published>
    <updated>2019-10-10T22:07:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>Different people mean different things, when they talk about <code>observability</code>. To stay practical and concrete, by observability I mean <code>monitoring, tracing and logging</code>. In this post I will give recipe of adding monitoring to your Spring Boot service with Prometheus and Grafana.</p></div><div class="paragraph"><p><strong>TL;DR</strong> If you prefer reading code vs reading posts&#8201;&#8212;&#8201;just follow this <a href="https://github.com/zghurskyi/investigations/tree/master/investigation-micrometer" target="_blank" rel="noopener">link</a>.</p></div><a id="more"></a><div class="sect1"><h2>What will we build?</h2><div class="sectionbody"><div class="paragraph"><p>I will follow simple plan:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Setup vanilla Spring Boot service (straight from <a href="https://start.spring.io" class="bare" target="_blank" rel="noopener">https://start.spring.io</a>)</p></li><li><p>Setup Prometheus</p></li><li><p>Setup Grafana</p></li><li><p>Perform some basic load testing and observe results</p></li></ol></div><div class="paragraph"><p>So, let&#8217;s start.</p></div></div></div><div class="sect1"><h2>1. Bootstrapping Spring Boot service</h2><div class="sectionbody"><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">$ curl https://start.spring.io/starter.zip \-d dependencies=actuator,webflux,lombok \-d type=maven-project \-d baseDir=service \-d groupId=com.oxymorus.monitoring \-d artifactId=service \-d bootVersion=2.1.9.RELEASE \-o service.zip$ unzip service.zip &amp;&amp; rm service.zip &amp;&amp; cd service</code></pre></div></div><div class="paragraph"><p>After bootstrapping bare-bones service, let&#8217;s prepare next steps by creating <code>monitoring</code> directory. This will be our base directory, where we place scripts and configs for Prometheus and Grafana:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">$ mkdir monitoring &amp;&amp; cd monitoring</code></pre></div></div></div></div><div class="sect1"><h2>2. Setting-up Prometheus</h2><div class="sectionbody"><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content"><a href="https://prometheus.io/docs/introduction/overview/" target="_blank" rel="noopener">Prometheus</a> is an open-source systems monitoring and alerting toolkit.</td></tr></table></div><div class="paragraph"><p>Spring Boot provides monitoring data in Promethues format through <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html#production-ready-metrics-export-prometheus" target="_blank" rel="noopener">/actuator/prometheus</a> endpoint. So, first, we need to expose this endpoint in <code>application.yml</code>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">management:  endpoints:    web:      exposure:        include:          - prometheus</code></pre></div></div><div class="paragraph"><p>Next, we need to configure scrapping of exposed endpoint by Prometheus. To do this, we provide <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/" target="_blank" rel="noopener">prometheus.yml</a>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># my global configglobal:  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.  # scrape_timeout is set to the global default (10s).# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files:# - "first_rules.yml"# - "second_rules.yml"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs:  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.  - job_name: 'prometheus'    # metrics_path defaults to '/metrics'    # scheme defaults to 'http'.    static_configs:      - targets: ['127.0.0.1:9090']  - job_name: 'spring-actuator'    metrics_path: '/actuator/prometheus'    scrape_interval: 5s    static_configs:      - targets: ['127.0.0.1:8080']</code></pre></div></div><div class="paragraph"><p>Finally, we can launch Promethues with Docker using following script:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">#!/bin/shdocker run --net=host -p 9090:9090 \-v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \prom/prometheus:v2.2.0</code></pre></div></div><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content">Don&#8217;t forget to make script executable with <code>chmod +x prometheus.sh</code></td></tr></table></div><div class="paragraph"><p>The script starts Prometheus on port 9090 and configures it to scrape Spring Boot <code>/actuator/prometheus</code> endpoint.</p></div><div class="paragraph"><p>We can check that everything is working by visiting default dashboard at <code>localhost:9090</code>:</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/prometheus-dashboard.png"><img src="/images/prometheus-dashboard.png" alt="prometheus dashboard"></a></div></div></div></div></div></div><div class="sect1"><h2>3. Setting-up Grafana</h2><div class="sectionbody"><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content"><a href="https://grafana.com/docs/v4.3/" target="_blank" rel="noopener">Grafana</a> is an open source metric analytics &amp; visualization suite. It is most commonly used for visualizing time series data for infrastructure and application analytics but many use it in other domains including industrial sensors, home automation, weather, and process control.</td></tr></table></div><div class="paragraph"><p>Grafana uses <a href="https://grafana.com/docs/guides/basic_concepts/" target="_blank" rel="noopener">dashboards</a> to organize your monitoring/metrics visualisation. So, we will preconfigure several dashboards:</p></div><div class="ulist"><ul><li><p><a href="https://github.com/zghurskyi/investigations/blob/master/investigation-micrometer/monitoring/dashboards/jvmgc-dashboard.json" target="_blank" rel="noopener">JVM garbage collection stats</a></p></li><li><p><a href="https://github.com/zghurskyi/investigations/blob/master/investigation-micrometer/monitoring/dashboards/latency-dashboard.json" target="_blank" rel="noopener">Latency stats&#8201;&#8212;&#8201;max &amp; 99th percentile</a></p></li><li><p><a href="https://github.com/zghurskyi/investigations/blob/master/investigation-micrometer/monitoring/dashboards/processor-dashboard.json" target="_blank" rel="noopener">Processor/CPU load</a></p></li></ul></div><div class="paragraph"><p>To provision these dashboards we need to provide <a href="https://grafana.com/docs/administration/provisioning/#dashboards" target="_blank" rel="noopener">grafana-dashboard.yml</a>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: 1providers:  - name: 'default'    folder: 'Spring Boot'    type: file    options:      path: /etc/grafana/dashboards</code></pre></div></div><div class="paragraph"><p>Next, to connect Grafana with Prometheus as its datasource we should provide <a href="https://grafana.com/docs/administration/provisioning/#datasources" target="_blank" rel="noopener">grafana-datasource.yml</a>:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: 1datasources:  - name: prometheus    type: prometheus    access: direct    url: http://127.0.0.1:9090</code></pre></div></div><div class="paragraph"><p>Finally, after all preparation we can start Grafana with following script:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">#!/bin/shdocker run -i --net=host \-p 3000:3000 \-v $(pwd)/grafana-datasource.yml:/etc/grafana/provisioning/datasources/grafana-datasource.yml \-v $(pwd)/dashboards/grafana-dashboard.yml:/etc/grafana/provisioning/dashboards/grafana-dashboard.yml \-v $(pwd)/dashboards/jvmgc-dashboard.json:/etc/grafana/dashboards/jvmgc.json \-v $(pwd)/dashboards/latency-dashboard.json:/etc/grafana/dashboards/latency.json \-v $(pwd)/dashboards/processor-dashboard.json:/etc/grafana/dashboards/processor.json \grafana/grafana:5.1.0</code></pre></div></div><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content">Don&#8217;t forget to make script executable with <code>chmod +x prometheus.sh</code></td></tr></table></div><div class="paragraph"><p>The script starts Grafana on <code>localhost:3000</code>.</p></div><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content">To login use default admin/admin credentials.</td></tr></table></div><div class="paragraph"><p>To verify everything is working, check preconfigured JVM GC dashboard:</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-dashboard.png"><img src="/images/grafana-dashboard.png" alt="grafana dashboard"></a></div></div></div></div></div></div><div class="sect1"><h2>4. Perform some basic load testing and observe results</h2><div class="sectionbody"><div class="paragraph"><p>After service is running and monitoring is properly configured, we can perform some load testing and observe how service behaves.</p></div><div class="paragraph"><p>For load testing we will use simple command line utility <a href="https://httpd.apache.org/docs/2.4/programs/ab.html" target="_blank" rel="noopener">Apache Benchmark</a>.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ ab -n 1000000 -c 10 http://localhost:8080/actuator/prometheus</code></pre></div></div><div class="paragraph"><p>This command performs 1 million requests in 10 concurrent threads to the <code><a href="http://localhost:8080/actuator/prometheus" class="bare" target="_blank" rel="noopener">http://localhost:8080/actuator/prometheus</a></code>.</p></div><div class="paragraph"><p>So, it&#8217;s time to observe some results:</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-heap-utilization.png"><img src="/images/grafana-heap-utilization.png" alt="grafana heap utilization"></a></div></div></div></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-average-gc-pause-time.png"><img src="/images/grafana-average-gc-pause-time.png" alt="grafana average gc pause time"></a></div></div></div></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-max-latency-by-endpoint.png"><img src="/images/grafana-max-latency-by-endpoint.png" alt="grafana max latency by endpoint"></a></div></div></div></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-request-throughput.png"><img src="/images/grafana-request-throughput.png" alt="grafana request throughput"></a></div></div></div></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/grafana-cpu-load.png"><img src="/images/grafana-cpu-load.png" alt="grafana cpu load"></a></div></div></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>It&#8217;s actually straight-forward to setup some basic Prometheus/Grafana monitoring, since all tools are already in place and fit together pretty well.</p></div><div class="paragraph"><p>Available tools allow to get comprehensive view of the system.</p></div><div class="paragraph"><p>Next step, after having this harness in place, is to configure custom metrics with Micrometer and make sense from all of them. I&#8217;m saving it for the next time, so stay tuned!</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Different people mean different things, when they talk about &lt;code&gt;observability&lt;/code&gt;. To stay practical and concrete, by observability I mean &lt;code&gt;monitoring, tracing and logging&lt;/code&gt;. In this post I will give recipe of adding monitoring to your Spring Boot service with Prometheus and Grafana.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; If you prefer reading code vs reading posts&amp;#8201;&amp;#8212;&amp;#8201;just follow this &lt;a href=&quot;https://github.com/zghurskyi/investigations/tree/master/investigation-micrometer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;link&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Observability" scheme="https://www.oxymorus.com/categories/observability/"/>
    
      <category term="Spring Boot" scheme="https://www.oxymorus.com/categories/observability/spring-boot/"/>
    
      <category term="Prometheus" scheme="https://www.oxymorus.com/categories/observability/spring-boot/prometheus/"/>
    
      <category term="Grafana" scheme="https://www.oxymorus.com/categories/observability/spring-boot/prometheus/grafana/"/>
    
      <category term="Docker" scheme="https://www.oxymorus.com/categories/observability/spring-boot/prometheus/grafana/docker/"/>
    
    
      <category term="Docker" scheme="https://www.oxymorus.com/tags/docker/"/>
    
      <category term="Observability" scheme="https://www.oxymorus.com/tags/observability/"/>
    
      <category term="Spring Boot" scheme="https://www.oxymorus.com/tags/spring-boot/"/>
    
      <category term="Prometheus" scheme="https://www.oxymorus.com/tags/prometheus/"/>
    
      <category term="Grafana" scheme="https://www.oxymorus.com/tags/grafana/"/>
    
  </entry>
  
  <entry>
    <title>From Java 8 to 11: quick tour</title>
    <link href="https://www.oxymorus.com/language-features-java8-to-java11/"/>
    <id>https://www.oxymorus.com/language-features-java8-to-java11/</id>
    <published>2019-06-27T18:07:41.000Z</published>
    <updated>2019-10-17T23:19:41.000Z</updated>
    
    <content type="html"><![CDATA[<div id="toc" class="toc"><div id="toctitle">Contents</div><ul class="sectlevel1"><li><a href="#">1. Java 8 to Java 11 language changes</a><ul class="sectlevel2"><li><a href="#">1.1. Language Changes for Java SE 9</a><ul class="sectlevel3"><li><a href="#">Platform module system</a></li><li><a href="#">Collections <em>.of()</em> factory methods</a></li><li><a href="#">Stream API changes</a></li><li><a href="#">Optional API changes</a></li><li><a href="#">Process Management API</a></li><li><a href="#">StackWalker</a></li><li><a href="#">More concise <code>try-with-resources</code> statements</a></li><li><a href="#">Private interface methods</a></li><li><a href="#">The underscore character is not a legal name</a></li></ul></li><li><a href="#">1.2. Language Changes for Java SE 10</a><ul class="sectlevel3"><li><a href="#">Local-Variable Type Inference with <code>var</code></a></li></ul></li><li><a href="#">1.3. Language Changes for Java SE 11</a><ul class="sectlevel3"><li><a href="#">Implicitly typed lambda expression</a></li></ul></li></ul></li><li><a href="#">2. Java and Docker</a></li></ul></div><div class="sect1"><h2>1. Java 8 to Java 11 language changes</h2><div class="sectionbody"><div class="sect2"><h3>1.1. Language Changes for Java SE 9</h3><div class="sect3"><h4>Platform module system</h4><div class="paragraph"><p>The major change to Java 9 is the introduction of the Java Platform module system.</p></div><div class="paragraph"><p>The Java Platform module system introduces a new kind of Java programming component&#8201;&#8212;&#8201;the module, which is a named, self-describing collection of code and data. Its code is organized as a set of packages containing types (i.e., Java classes and interfaces). Its data includes resources and other kinds of static information. Modules can either export or encapsulate packages, and they express dependencies on other modules explicitly.</p></div><div class="paragraph"><p>To learn more about the Java Platform module system, see <a href="http://openjdk.java.net/projects/jigsaw/" target="_blank" rel="noopener">Project Jigsaw</a> on OpenJDK.</p></div></div><div class="sect3"><h4>Collections <em>.of()</em> factory methods</h4><div class="paragraph"><p>Java 9 introduces collection literals for the easier definition of the common collections:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">List list = List.of(1, 2, 3);Set set = Set.of("foo", "bar", "baz");Map map = Map.of("hello", "world");Map mapOfEntries = Map.ofEntries(Map.entry("o", 0), Map.entry("z", 1));</code></pre></div></div></div><div class="sect3"><h4>Stream API changes</h4><div class="sect4"><h5><code>takeWhile</code></h5><div class="paragraph"><p>takeWhile takes elements from the initial stream while the predicate holds true. Meaning that when an element is encountered that does not match the predicate, the rest of the stream is discarded.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Stream.of(2, 4, 6, 8, 9, 10, 12)      .takeWhile(n -&gt; n % 2 == 0)      .forEach(System.out::print); // 2468</code></pre></div></div></div><div class="sect4"><h5><code>dropWhile</code></h5><div class="paragraph"><p>dropWhile is essentially the opposite of takeWhile. Instead of taking elements from the stream until the first element which does not match the predicate, dropWhile drops these elements and includes the remaining elements in the returned stream.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Stream.of(2, 4, 6, 8, 9, 10, 12)      .dropWhile(n -&gt; n % 2 == 0)      .forEach(System.out::print); // 91012</code></pre></div></div></div></div><div class="sect3"><h4>Optional API changes</h4><div class="sect4"><h5><code>or()</code> method</h5><div class="paragraph"><p>The <code>or()</code> method gives you a fluent way of chaining behavior on <code>Optional</code> without checking if the value is present or not.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Optional.empty().or(() -&gt; Optional.of("Hello world"));</code></pre></div></div></div><div class="sect4"><h5>Converting an <code>Optional</code> into a <code>Stream</code></h5><div class="paragraph"><p>Now it&#8217;s possible to convert an <code>Optional</code> into a <code>Stream</code> containing at most one element. Its really useful if you want to use the laziness of the <em>Streams API</em>. Namely, calling <code>map()</code> on the <code>Optional</code> executes the mapping function immediately, on the <code>Stream</code>&#8201;&#8212;&#8201;not.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Optional optional = Optional.of(1).map(x -&gt; x * 3); // variable contains Optional[3]Stream stream = Optional.of(1).stream().map(x -&gt; x * 3); // variable contains lazy stream, that is not evaluated until terminal operation</code></pre></div></div></div><div class="sect4"><h5><em>ifPresentOrElse()</em> method</h5><div class="paragraph"><p>In Java 8 you could specify the behavior you want to execute if the value in an <code>Optional</code> is present.</p></div><div class="paragraph"><p>In Java 9 you can pass 2 Runnables to specify what to do if the value is present and otherwise.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Optional.empty().ifPresentOrElse(x -&gt; System.out.println(x), () -&gt; System.out.println("empty")); // empty</code></pre></div></div></div></div><div class="sect3"><h4>Process Management API</h4><div class="paragraph"><p>Java 9 adds the <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/ProcessHandle.html" target="_blank" rel="noopener">ProcessHandle</a> class, which offers a rich API to inspect the processes.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ProcessHandle current = ProcessHandle.current(); current.pid() // prints current process id</code></pre></div></div></div><div class="sect3"><h4>StackWalker</h4><div class="paragraph"><p><a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/StackWalker.html" target="_blank" rel="noopener">StackWalker</a> enables you to walk, filter and otherwise access stack traces in a very efficient manner</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">StackWalker.getInstance()           .walk(s -&gt; s.limit(5)           .collect(Collectors.toList()));</code></pre></div></div></div><div class="sect3"><h4>More concise <code>try-with-resources</code> statements</h4><div class="paragraph"><p>If you already have a resource as a final or effectively final variable, you can use that variable in a <code>try-with-resources</code> statement without declaring a new variable. An "effectively final" variable is one whose value is never changed after it is initialized.</p></div><div class="paragraph"><p>In Java SE 7 or 8, you would declare new variables, like this:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">try (Resource r1 = resource1; Resource r2 = resource2) {    // do something}</code></pre></div></div><div class="paragraph"><p>In Java SE 9 and beyond, you dont need to declare r1 and r2 in a <code>try-with-resources</code> statement:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">try (resource1; resource2) {    // do something}</code></pre></div></div></div><div class="sect3"><h4>Private interface methods</h4><div class="paragraph"><p>Private interface methods are supported. This support allows non-abstract methods of an interface to share code between them.</p></div></div><div class="sect3"><h4>The underscore character is not a legal name</h4><div class="paragraph"><p>If you use the underscore character (<code>"_"</code>) an identifier, your source code can no longer be compiled.</p></div></div></div><div class="sect2"><h3>1.2. Language Changes for Java SE 10</h3><div class="paragraph"><p>Java SE 10 introduces support for inferring the type of local variables from the context, which makes code more readable and reduces the amount of required boilerplate code.</p></div><div class="sect3"><h4>Local-Variable Type Inference with <code>var</code></h4><div class="paragraph"><p>In Java SE 10 and later, you can declare local variables with non-null initializers with the <code>var</code> identifier, which can help you write code thats easier to read.</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">URL url = new URL("http://www.oracle.com/");URLConnection conn = url.openConnection();Reader reader = new BufferedReader(new InputStreamReader(conn.getInputStream()));</code></pre></div></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">var url = new URL("www.oracle.com");var conn = url.openConnection();var reader = new BufferedReader(new InputStreamReader(conn.getInputStream()));</code></pre></div></div><div class="paragraph"><p><code>var</code> is a reserved type name, not a keyword, which means that existing code that uses <code>var</code> as a variable, method,or package name is not affected. However, code that uses <code>var</code> as a class or interface name is affected and the class or interface needs to be renamed.</p></div><div class="paragraph"><p><code>var</code> can be used for the following types of variables:</p></div><div class="ulist"><ul><li><p>Local variable declarations with initializers:</p><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">var list = new ArrayList(); // infers ArrayListvar stream = list.stream(); // infers Streamvar path = Paths.get(fileName); // infers Pathvar bytes = Files.readAllBytes(path); // infers bytes[]</code></pre></div></div></li><li><p>Enhanced <code>for-loop</code> indexes:</p><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">List myList = Arrays.asList("a", "b", "c");for (var element : myList) { ... } // infers String</code></pre></div></div></li><li><p>Index variables declared in traditional <code>for-loop</code>:</p><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">for (var counter = 0; counter &lt; 10; counter++) {...} // infers int</code></pre></div></div></li><li><p><code>try-with-resources</code> variable:</p><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">try (var input = new FileInputStream("validation.txt")) {...} // infers FileInputStream</code></pre></div></div></li><li><p>A lambda expression whose formal parameters have inferred types is implicitly typed:</p><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">BiFunction = (a, b) -&gt; a + b</code></pre></div></div></li></ul></div><div class="paragraph"><p><strong><code>var</code> style guide:</strong> <code>var</code> should be used with caution. To get more details about recommended uses,consult with official <a href="https://openjdk.java.net/projects/amber/LVTIstyle.html" target="_blank" rel="noopener">style guide</a>.</p></div></div></div><div class="sect2"><h3>1.3. Language Changes for Java SE 11</h3><div class="sect3"><h4>Implicitly typed lambda expression</h4><div class="paragraph"><p>In Java SE 11 and later, you can declare each formal parameter of an implicitly typed lambda expression with the <code>var</code> identifier:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">(var a, var b) -&gt; a + b;</code></pre></div></div><div class="paragraph"><p>Why would we want to use <code>var</code> for lambda parameters when we could simply skip the types?</p></div><div class="paragraph"><p>One benefit of uniformity is that annotations can be applied to lambda parameters:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">(@Nonnull var s1, @Nullable var s2) -&gt; s1 + s2</code></pre></div></div></div></div></div></div><div class="sect1"><h2>2. Java and Docker</h2><div class="sectionbody"><div class="paragraph"><p>One of the key features of Docker is the ability to limit a containers memory and CPU usage. Unfortunately, this is precisely where Java runs short. Lets use an example to understand the problem. Imagine you have a node with 32GB of memory and you want to run a Java application with a limit of 1GB. If you do not provide a <code>-Xmx</code> parameter the JVM will use its default configuration:</p></div><div class="olist arabic"><ol class="arabic"><li><p>The JVM will check the total available memory. Because the JVM is not aware of the Linux container, it thinks it is running on the Host machine and has access to the full 32GB of available memory.</p></li><li><p>By default, the JVM will use <code>MaxMemory/4</code> which in this case is 8GB (32GB/4).</p></li><li><p>As the heap size grows and goes beyond 1GB, the container will be killed by Docker (<code>"OOM killed"</code>).</p></li><li><p>Of course, an obvious solution is to fix the JVMs heap size using <code>-Xmx</code> parameter, but that means you need to control memory twice, once in Docker and once in the JVM.</p></li></ol></div><div class="paragraph"><p>The first workaround for this issue was released with Java 8u131 and Java 9:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Use <code>-XX:+UnlockExperimentalVMOptions</code></p></li><li><p>Use <code>-XX:+UseCGroupMemoryLimitForHeap</code> which would tell the JVM to check for the cgroup memory limit to set the maximum heap size</p></li><li><p>Use <code>-XX:MaxRAMFraction</code>, to limit portion of memory that can be allocated to the JVM.</p></li><li><p>Finally, application should control explicitly the thread pools sizes, and limit common ForkJoinPool parallelism with <code>-Djava.util.concurrent.ForkJoinPool.common.parallelism=2</code></p></li></ol></div><div class="paragraph"><p>So, with Java 8u131+ and Java 9 youd have something like:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">-XX:+UnlockExperimentalVMOptions-XX:+UseCGroupMemoryLimitForHeap-XX:MaxRAMFraction=2-Djava.util.concurrent.ForkJoinPool.common.parallelism=2</code></pre></div></div><div class="paragraph"><p>Starting from Java 10 applying CPU and memory limits to containerized JVMs becomes straightforward. The JVM will detect hardware capability of the container correctly, tune itself appropriately and make a good representation of the available capacity to the application. As a result, not only CPU Sets but also CPU Shares are now examined by JVM. Furthermore, this becomes the default behaviour, and can only be disabled via <code>-XX:-UseContainerSupport</code> option.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div id=&quot;toc&quot; class=&quot;toc&quot;&gt;&lt;div id=&quot;toctitle&quot;&gt;Contents&lt;/div&gt;&lt;ul class=&quot;sectlevel1&quot;&gt;&lt;li&gt;&lt;a href=&quot;#&quot;&gt;1. Java 8 to Java 11 language changes&lt;/a&gt;&lt;
      
    
    </summary>
    
      <category term="Java" scheme="https://www.oxymorus.com/categories/java/"/>
    
      <category term="Java 9" scheme="https://www.oxymorus.com/categories/java/java-9/"/>
    
      <category term="Java 10" scheme="https://www.oxymorus.com/categories/java/java-9/java-10/"/>
    
      <category term="Java 11" scheme="https://www.oxymorus.com/categories/java/java-9/java-10/java-11/"/>
    
    
      <category term="Java" scheme="https://www.oxymorus.com/tags/java/"/>
    
      <category term="Java 9" scheme="https://www.oxymorus.com/tags/java-9/"/>
    
      <category term="Java 10" scheme="https://www.oxymorus.com/tags/java-10/"/>
    
      <category term="Java 11" scheme="https://www.oxymorus.com/tags/java-11/"/>
    
  </entry>
  
  <entry>
    <title>Lost Update Phenomena</title>
    <link href="https://www.oxymorus.com/lost-update/"/>
    <id>https://www.oxymorus.com/lost-update/</id>
    <published>2019-06-21T23:19:41.000Z</published>
    <updated>2019-10-15T23:19:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p><a href="https://en.wikipedia.org/wiki/Write%E2%80%93write_conflict" target="_blank" rel="noopener">An update is lost</a> when a user overrides the current database state without realizing, that someone else changed it between the moment of data loading and the moment the update occurs. In this post, I will give detailed description of this phenomena and typical ways to prevent it.</p></div><a id="more"></a><div class="sect1"><h2>Lost Update Phenomena</h2><div class="sectionbody"><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/lost_update.png"><img src="/images/lost_update.png" alt="lost update"></a></div></div></div></div><div class="paragraph"><p>There are several approaches to prevent the problem:</p></div><div class="ulist"><ul><li><p>Change isolation level</p></li><li><p>Use pessimistic locking (<code>SELECT &#8230;&#8203; FOR UPDATE</code>)</p></li><li><p>Use optimistic locking (version or timestamp based)</p></li></ul></div></div></div><div class="sect1"><h2>Changing isolation level</h2><div class="sectionbody"><div class="paragraph"><p>Most databases use <code>READ COMMITTED</code> isolation level by default (MySQL - <code>REPEATABLE READ</code>). Choosing isolation level is always a trade-off between consistency and scalability.</p></div><div class="paragraph"><p>If lost update is pretty common scenario in the system, sometime it will make sense to use higher isolation level. For example, either <code>REPEATABLE READ</code> or <code>SERIALIZABLE</code> will prevent lost update from happening.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/lost_update_isolation_level.png"><img src="/images/lost_update_isolation_level.png" alt="lost update isolation level"></a></div></div></div></div><div class="paragraph"><p>In the situation above, if two transactions try to change the same record, the second will be forced to wait while the first either commits or rollbacks. And if the first transaction commits, the second will be aborted.</p></div><div class="paragraph"><p>The drawback of such approach, is that isolation level is set per database connection, that is not desirable or acceptable in most cases.</p></div></div></div><div class="sect1"><h2>Using pessimistic locking</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/pessimisticOfflineLock.html" target="_blank" rel="noopener">Pessimistic locking</a> is a common tool used to maintain data consistency.</p></div><div class="paragraph"><p>In relational databases it is usually achieved by using <code>SELECT &#8230;&#8203; FOR UPDATE</code> with default <code>READ COMMITTED</code> isolation level (these combination will lead to acquiring write lock).</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/lost_update_pessimistic_locking.png"><img src="/images/lost_update_pessimistic_locking.png" alt="lost update pessimistic locking"></a></div></div></div></div><div class="paragraph"><p>So, if two transactions try to change the same record, the second will be forced to wait while the first either commits or rollbacks. After first transaction terminates, the second one will see changes and, therefore, no updates will be lost.</p></div><div class="paragraph"><p>It should be mentioned, that <strong>both</strong> transactions should acquire write locks, otherwise lost update won&#8217;t be prevented.</p></div></div></div><div class="sect1"><h2>Using optimistic locking</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://martinfowler.com/eaaCatalog/optimisticOfflineLock.html" target="_blank" rel="noopener">The optimistic locking</a> doesn&#8217;t rely on acquiring write locks. It uses versioning to detect, that data was changed concurrently. If two transactions try to change the same record, the second one won&#8217;t change anything since it will use version, that no longer exist.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/lost_update_optimistic_locking.png"><img src="/images/lost_update_optimistic_locking.png" alt="lost update optimistic locking"></a></div></div></div></div><div class="paragraph"><p>So, every <code>UPDATE</code> will take version into the <code>WHERE</code> clause. Basically, it optimistically assumes, that no one changing the row concurrently. However, if another transaction commits a newer record version, the second transaction will no longer match any row and therefore the lost update is prevented.</p></div><div class="paragraph"><p>ORMs (e.g. Hibernate) use updated results count to check the number of updated rows. If no row was matched, <a href="https://docs.oracle.com/javaee/7/api/javax/persistence/OptimisticLockException.html" target="_blank" rel="noopener">OptimisticLockException</a> is thrown. After exception is thrown, the current transaction and persistence context are aborted.</p></div></div></div><div class="sect1"><h2>References</h2><div class="sectionbody"><div class="olist arabic"><ol class="arabic"><li><p><a href="https://martinfowler.com/eaaCatalog/pessimisticOfflineLock.html" target="_blank" rel="noopener">Pessimistic offline locking</a></p></li><li><p><a href="https://martinfowler.com/eaaCatalog/optimisticOfflineLock.html" target="_blank" rel="noopener">Optimistic offline locking</a></p></li><li><p><a href="https://vladmihalcea.com/a-beginners-guide-to-database-locking-and-the-lost-update-phenomena/" target="_blank" rel="noopener">A beginners guide to database locking and the lost update phenomena</a></p></li></ol></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Write%E2%80%93write_conflict&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;An update is lost&lt;/a&gt; when a user overrides the current database state without realizing, that someone else changed it between the moment of data loading and the moment the update occurs. In this post, I will give detailed description of this phenomena and typical ways to prevent it.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Data Access Layer" scheme="https://www.oxymorus.com/categories/data-access-layer/"/>
    
      <category term="Lost Update" scheme="https://www.oxymorus.com/categories/data-access-layer/lost-update/"/>
    
      <category term="Isolation" scheme="https://www.oxymorus.com/categories/data-access-layer/lost-update/isolation/"/>
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/categories/data-access-layer/lost-update/isolation/pessimistic-locking/"/>
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/categories/data-access-layer/lost-update/isolation/pessimistic-locking/optimistic-locking/"/>
    
    
      <category term="Data Access Layer" scheme="https://www.oxymorus.com/tags/data-access-layer/"/>
    
      <category term="Lost Update" scheme="https://www.oxymorus.com/tags/lost-update/"/>
    
      <category term="Isolation" scheme="https://www.oxymorus.com/tags/isolation/"/>
    
      <category term="Pessimistic Locking" scheme="https://www.oxymorus.com/tags/pessimistic-locking/"/>
    
      <category term="Optimistic Locking" scheme="https://www.oxymorus.com/tags/optimistic-locking/"/>
    
  </entry>
  
  <entry>
    <title>Kafka Provision Spring Boot Starter</title>
    <link href="https://www.oxymorus.com/kafka-provision-spring-boot-starter/"/>
    <id>https://www.oxymorus.com/kafka-provision-spring-boot-starter/</id>
    <published>2019-06-21T22:39:55.000Z</published>
    <updated>2019-10-07T22:39:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p><a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a> enables distributed Kafka topics provisioning and centralized topic configs management.</p></div><a id="more"></a><div class="sect1"><h2>Overview</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a> supports following set of features:</p></div><div class="ulist"><ul><li><p>creating new topics</p></li><li><p>adding partitions to the existing topics</p></li><li><p>setting/updating topic configurations</p></li></ul></div><div class="paragraph"><p>In this post I will describe the process of creating application, that uses the starter.</p></div></div></div><div class="sect1"><h2>Demo application description</h2><div class="sectionbody"><div class="paragraph"><p>To not overshadow main goal, the demo application will be really simple. We will create 2 "microservices":</p></div><div class="ulist"><ul><li><p>The first service will produce tasks and push them to the <code>tasks</code> topic</p></li><li><p>The second service will pull the tasks from the topic, sleep randomly and send events to <code>results</code> topic</p></li></ul></div><div class="paragraph"><p>So, everything sounds really simple - let&#8217;s overengineer it as much as possible!</p></div></div></div><div class="sect1"><h2>Setting up basic Spring Boot services</h2><div class="sectionbody"><div class="paragraph"><p>First, let&#8217;s bootstrap Spring Boot app with Spring Cloud Stream, Spring Kafka and Lombok support:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ curl https://start.spring.io/starter.zip \-d dependencies=cloud-stream,kafka,lombok \-d type=gradle-project \-d baseDir=task-producer \-d groupId=com.oxymorus.kafka.producer \-d artifactId=task-producer \-o task-producer.zip$ unzip task-producer.zip &amp;&amp; rm task-producer.zip</code></pre></div></div><div class="paragraph"><p>Just a quick note: Spring Cloud Stream is a framework for building highly scalable event-driven microservices connected with shared messaging systems.</p></div><div class="paragraph"><p>The core building blocks of Spring Cloud Stream are:</p></div><div class="ulist"><ul><li><p>Destination Binders: Components responsible to provide integration with the external messaging systems.</p></li><li><p>Destination Bindings: Bridge between the external messaging systems and application provided Producers and Consumers of messages (created by the Destination Binders).</p></li><li><p>Message: The canonical data structure used by producers and consumers to communicate with Destination Binders (and thus other applications via external messaging systems).</p></li></ul></div><div class="paragraph"><p>To get more detail just read the official reference <a href="https://cloud.spring.io/spring-cloud-static/spring-cloud-stream/2.1.2.RELEASE/single/spring-cloud-stream.html#_main_concepts" target="_blank" rel="noopener">here.</a></p></div><div class="paragraph"><p>Ok, let&#8217;s get back to our main course and bootstrap task-consumer service:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ curl https://start.spring.io/starter.zip -d dependencies=cloud-stream,kafka,lombok \-d type=gradle-project \-d baseDir=task-consumer \-d groupId=com.oxymorus.kafka.consumer \-d artifactId=task-consumer \-o task-consumer.zip$ unzip task-consumer.zip &amp;&amp; rm task-consumer.zip</code></pre></div></div></div></div><div class="sect1"><h2>Configuring Kafka topics</h2><div class="sectionbody"><div class="paragraph"><p>As described earlier two created services will communicate over Kafka topics: <code>tasks</code> and <code>results</code>. So, we need to create &amp; configure these topics. Here, comes the time for <a href="https://github.com/zghurskyi/kafka-provision-spring-boot-starter" target="_blank" rel="noopener">Kafka Provision Spring Boot Starter</a>.</p></div><div class="paragraph"><p>We will do this in three steps:</p></div><div class="olist arabic"><ol class="arabic"><li><p>Add dependency</p></li><li><p>Add @EnableTopicProvisioning</p></li><li><p>Configure topics</p></li></ol></div><div class="paragraph"><p>Let&#8217;s do this procedure step-by-step for task-producer service. First, let&#8217;s add dependency to build.gradle:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">dependencies {    implementation 'io.github.zghurskyi.kafka:kafka-provision-spring-boot-starter:0.0.1'}</code></pre></div></div><div class="paragraph"><p>Next, let&#8217;s add @EnableTopicProvisioning to TaskProducerApp class:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.oxymorus.kafka.producer;import io.github.zghurskyi.kafka.EnableTopicProvisioning;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication@EnableTopicProvisioningpublic class TaskProducerApp {  public static void main(String[] args) {    SpringApplication.run(TaskProducerApp.class, args);  }}</code></pre></div></div><div class="paragraph"><p>And finally, let&#8217;s configure required topics:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka.provision:  brokers: localhost:9092  topics:  - name: tasks    numPartitions: 4    replicationFactor: 1    configs:      cleanup.policy: delete      retention.ms: 3600000  - name: results    numPartitions: 4    replicationFactor: 1    configs:      cleanup.policy: delete      retention.ms: 3600000</code></pre></div></div><div class="paragraph"><p>The above steps are similar for <code>task-consumer</code> service.</p></div><div class="paragraph"><p>The details of setting up Spring Cloud Stream &amp; Kafka in Spring Boot app deserve separate blog post, so to just stay on point I will skip them. You can find completed demo app <a href="https://github.com/zghurskyi/kafka-provision-examples" target="_blank" rel="noopener">here</a>.</p></div></div></div><div class="sect1"><h2>Setting up Kafka infrastructure</h2><div class="sectionbody"><div class="paragraph"><p>For the purposes of this demo we set up infrastructure with following docker-compose.yml:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">version: '3'services:    kafka:        image: confluentinc/cp-kafka:latest        container_name: kafka        ports:        - "9092:9092"        depends_on:        - zookeeper        environment:          KAFKA_BROKER_ID: 1          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1          KAFKA_MESSAGE_MAX_BYTES: 10000000    zookeeper:        image: confluentinc/cp-zookeeper:latest        container_name: zookeeper        ports:        - "2181:2181"        environment:          ZOOKEEPER_CLIENT_PORT: 2181          ZOOKEEPER_TICK_TIME: 2000          ZOOKEEPER_INIT_LIMIT: 5          ZOOKEEPER_SYNC_LIMIT: 2</code></pre></div></div></div></div><div class="sect1"><h2>Putting everything together</h2><div class="sectionbody"><div class="paragraph"><p>The time has come to start everything up:</p></div><div class="ulist"><ul><li><p>Boot up Kafka with docker-compose.yml:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ cd kafka-provision-examples/$ docker-compose up</code></pre></div></div><div class="ulist"><ul><li><p>Build and start <code>task-producer</code>:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ ./task-producer/gradlew -b ./task-producer/build.gradle clean build$ java -jar task-producer/build/libs/task-producer-0.0.1-SNAPSHOT.jar</code></pre></div></div><div class="ulist"><ul><li><p>Build and start <code>task-consumer</code>:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-shell script hljs" data-lang="shell script">$ ./task-consumer/gradlew -b ./task-consumer/build.gradle clean build$ java -jar task-consumer/build/libs/task-consumer-0.0.1-SNAPSHOT.jar</code></pre></div></div><div class="paragraph"><p>After starting everything up, we will see something like this in the logs:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-logs hljs" data-lang="logs">task_producer    | 2019-04-21 10:27:49.071  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=EAT, status=SUCCESS)task_producer    | 2019-04-21 10:27:49.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Published: TaskMessage(task=Task(action=SLEEP))task_producer    | 2019-04-21 10:27:49.413  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=WRITE_CODE, status=SUCCESS)task_producer    | 2019-04-21 10:27:50.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Published: TaskMessage(task=Task(action=SLEEP))task_producer    | 2019-04-21 10:27:50.826  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=EAT, status=FAIL)task_producer    | 2019-04-21 10:27:52.945  INFO 1 --- [container-0-C-1] c.o.kafka.bindings.ResultsListener       : Received: ResultMessage(action=SLEEP, status=SKIP_THIS_TIME)task_producer    | 2019-04-21 10:27:53.191  INFO 1 --- [   scheduling-1] c.o.kafka.bindings.TasksPublisher        : Received: ResultMessage(action=WRITE_CODE, status=SUCCESS)</code></pre></div></div><div class="paragraph"><p>This indicates, that everything works as it&#8217;s supposed to :)</p></div></div></div><div class="sect1"><h2>Checking topics configuration</h2><div class="sectionbody"><div class="paragraph"><p>Now let&#8217;s checkout Kafka topic configs, that were provisioned by starter:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-logs hljs" data-lang="logs">$ docker exec -ti kafka /bin/bashroot@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --list__confluent.support.metrics__consumer_offsetsresultstasksroot@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --describe --topic tasksTopic:tasks    PartitionCount:4    ReplicationFactor:1    Configs:retention.ms=360000,cleanup.policy=deleteTopic: tasks    Partition: 0    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 1    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 2    Leader: 1    Replicas: 1    Isr: 1Topic: tasks    Partition: 3    Leader: 1    Replicas: 1    Isr: 1root@4874c1726187:/# kafka-topics --zookeeper zookeeper:2181 --describe --topic resultsTopic:results    PartitionCount:4    ReplicationFactor:1    Configs:retention.ms=360000,cleanup.policy=deleteTopic: results    Partition: 0    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 1    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 2    Leader: 1    Replicas: 1    Isr: 1Topic: results    Partition: 3    Leader: 1    Replicas: 1    Isr: 1</code></pre></div></div><div class="paragraph"><p>So, as we can see Kafka Provision Spring boot starter has created required topics for us and added specified configs.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/zghurskyi/kafka-provision-spring-boot-starter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Kafka Provision Spring Boot Starter&lt;/a&gt; enables distributed Kafka topics provisioning and centralized topic configs management.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Apache Kafka" scheme="https://www.oxymorus.com/categories/apache-kafka/"/>
    
      <category term="Spring Boot Starter" scheme="https://www.oxymorus.com/categories/apache-kafka/spring-boot-starter/"/>
    
      <category term="Topic Provisioning" scheme="https://www.oxymorus.com/categories/apache-kafka/spring-boot-starter/topic-provisioning/"/>
    
    
      <category term="Apache Kafka" scheme="https://www.oxymorus.com/tags/apache-kafka/"/>
    
      <category term="Spring Boot Starter" scheme="https://www.oxymorus.com/tags/spring-boot-starter/"/>
    
      <category term="Topic Provisioning" scheme="https://www.oxymorus.com/tags/topic-provisioning/"/>
    
  </entry>
  
  <entry>
    <title>Relational Database Transaction</title>
    <link href="https://www.oxymorus.com/database-transaction/"/>
    <id>https://www.oxymorus.com/database-transaction/</id>
    <published>2019-06-20T00:53:41.000Z</published>
    <updated>2019-10-16T00:53:41.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>Database Transaction represents a unit of work, that is atomic, consistent, isolated and durable (a.k.a. <code>ACID</code>).</p></div><a id="more"></a><div class="sect1"><h2>Database Transaction</h2><div class="sectionbody"><div class="paragraph"><p><code>ACID</code> guarantees are provided by traditional relational database management systems (RDBMS).</p></div><div class="ulist"><ul><li><p><code>Atomicity</code> means that operations, that constitute transaction are all either succeed or fail together. So, atomicity implies that there can&#8217;t be situation, in which part of operations succeeded and part failed.</p></li><li><p><code>Consistency</code> means that transaction leaves database in consistent state after execution. So, in practical terms, any data written to database must be valid according to integrity constraints (primary key/foreign key/unique key/etc.), cascades, triggers, and any combination thereof.</p></li><li><p><code>Isolation</code> determines how operations performed in a transaction are visible to other executing transactions. So, for example, whether data written by transaction is available for read by other concurrent transactions.</p></li><li><p><code>Durability</code> means that after transaction is committed, database changes are saved permanently. So, if database crushes all committed transactions will be restored. This is most often implemented by using transaction log stored in non-volatile storage. And transaction is committed only after it is entered in the log.</p></li></ul></div></div></div><div class="sect1"><h2>Transaction states</h2><div class="sectionbody"><div class="paragraph"><p>During execution database transaction goes through number of states:</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/transaction_state_machine.png"><img src="/images/transaction_state_machine.png" alt="transaction state machine"></a></div></div></div></div><div class="sect2"><h3>State transitions example</h3><div class="paragraph"><p>Assume we have two accounts: one for Alice (account A) and one for Bob (account B). Initially each account has 1000$ balance. The task is to transfer 100$ from account A to account B.</p></div><div class="paragraph"><p>Database transaction for above situation can be represented as follows (in PostgreSQL syntax):</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sql hljs" data-lang="sql">BEGIN;UPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice'; <i class="conum" data-value="1"></i><b>(1)</b>UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Bob'; <i class="conum" data-value="2"></i><b>(2)</b>COMMIT;</code></pre></div></div><div class="paragraph"><p>Let&#8217;s follow state transitioning for this transaction:</p></div><div class="olist arabic"><ol class="arabic"><li><p>In <code>ACTIVE</code> state read/write operations on database are performed. So, any statements between <code>BEGIN</code> and <code>COMMIT</code> instructions form <code>ACTIVE</code> state.</p></li><li><p>If transaction reaches <code>COMMIT</code> without failures, then it goes into <code>PARTIALLY COMMITTED</code> state. In <code>PARTIALLY COMMITTED</code> state, balances will have values: A = 900 and B = 1100.</p></li><li><p>If the transaction executes <code>COMMIT</code> successfully, that is, if it successfully writes the new value of A and B into log file or stable storage, then the transaction is said to be in <code>COMMITTED</code> state.</p></li><li><p>Transaction may enter <code>FAILED</code> state:</p><div class="ulist"><ul><li><p>In <code>ACTIVE</code> state:</p><div class="olist loweralpha"><ol class="loweralpha" type="a"><li><p>before first <code>UPDATE</code> ended : then A = 1000 and B = 1000</p></li><li><p>after first <code>UPDATE</code> ended: then A = 900 and B = 1100</p></li><li><p>before <code>COMMIT</code> and after second <code>UPDATE</code>: then A = 900 and B = 1100</p></li></ol></div></li><li><p>In <code>PARTIALLY COMMITTED</code> state: then A = 900 and B = 1100</p></li></ul></div></li><li><p>The transaction enters <code>ABORTED</code> after rollback. In this state DBMS has to undo the changes made so far. So, whatever balances are at the beginning in <code>ABORTED</code> state, after roll back, the state will be reverted to the previous consistent state (A = 1000 and B = 1000)</p></li><li><p>After entering <code>COMMITTED</code> or <code>ABORTED</code> state, transaction is terminated</p></li></ol></div><div class="admonitionblock note"><table><tr><td class="icon"><i class="fa icon-note" title="Note"></i></td><td class="content"><div class="paragraph"><p><em>Why transaction may fail ?</em></p></div><div class="paragraph"><p>Database transaction might fail due to one or more of the following reasons:</p></div><div class="ulist"><ul><li><p>Server failure, e.g. hardware, software or network error, that causes database server to hang or crash</p></li><li><p>Logical transaction failure, e.g. user aborts transaction, division by zero etc.</p></li><li><p>Concurrency failure, e.g. if transaction causes deadlock, or violates serializability</p></li><li><p>Disk failure</p></li></ul></div><div class="paragraph"><p>DBMS usually can recover from server failure, logical failure or concurrency failure. To deal with disk failures - disk backups needs to be maintained.</p></div></td></tr></table></div></div></div></div><div class="sect1"><h2>Savepoints</h2><div class="sectionbody"><div class="paragraph"><p>It&#8217;s possible to control the statements in a transaction in a more granular fashion through the use of <a href="https://www.postgresql.org/docs/8.3/tutorial-transactions.html" target="_blank" rel="noopener">savepoints</a>. Savepoints allow you to selectively discard parts of the transaction, while committing the rest. After defining a savepoint with <code>SAVEPOINT</code>, you can if needed roll back to the savepoint with <code>ROLLBACK TO</code>. All the transaction&#8217;s database changes between defining the savepoint and rolling back to it are discarded, but changes earlier than the savepoint are kept.</p></div><div class="paragraph"><p>After rolling back to a savepoint, it continues to be defined, so you can roll back to it several times. Conversely, if you are sure you won&#8217;t need to roll back to a particular savepoint again, it can be released, so the system can free some resources. Keep in mind that either releasing or rolling back to a savepoint will automatically release all savepoints that were defined after it.</p></div><div class="paragraph"><p>Suppose we debit $100.00 from Alice&#8217;s account, and credit Bob&#8217;s account, only to find later that we should have credited Wally&#8217;s account. We could do it using savepoints like this:</p></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sql hljs" data-lang="sql">BEGIN;UPDATE accounts SET balance = balance - 100.00 WHERE name = 'Alice';SAVEPOINT my_savepoint;UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Bob';-- oops ... forget that and use Wally's accountROLLBACK TO my_savepoint;UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Wally';COMMIT;</code></pre></div></div><div class="paragraph"><p>This example is, of course, oversimplified, but there&#8217;s a lot of control to be had over a transaction block through the use of savepoints.</p></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Even though this post may seem pretty dry, however, it lays good foundation to get started working with transactions in your Data Access Layer.</p></div><div class="paragraph"><p>In the next posts I will comeback to this topic from more practical perspective in the context of our lovely Spring Boot services. So, stay tuned ;)</p></div></div></div><div class="sect1"><h2>References</h2><div class="sectionbody"><div class="paragraph"><p><a href="https://www.postgresql.org/docs/8.3/tutorial-transactions.html" target="_blank" rel="noopener">PostgreSQL documentation</a></p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Database Transaction represents a unit of work, that is atomic, consistent, isolated and durable (a.k.a. &lt;code&gt;ACID&lt;/code&gt;).&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Data Access Layer" scheme="https://www.oxymorus.com/categories/data-access-layer/"/>
    
      <category term="Transaction" scheme="https://www.oxymorus.com/categories/data-access-layer/transaction/"/>
    
      <category term="ACID" scheme="https://www.oxymorus.com/categories/data-access-layer/transaction/acid/"/>
    
    
      <category term="Data Access Layer" scheme="https://www.oxymorus.com/tags/data-access-layer/"/>
    
      <category term="Transaction" scheme="https://www.oxymorus.com/tags/transaction/"/>
    
      <category term="ACID" scheme="https://www.oxymorus.com/tags/acid/"/>
    
  </entry>
  
  <entry>
    <title>Back-pressure patterns in practice</title>
    <link href="https://www.oxymorus.com/backpressure/"/>
    <id>https://www.oxymorus.com/backpressure/</id>
    <published>2019-06-19T10:58:44.000Z</published>
    <updated>2019-10-07T10:58:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>Back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load.</p></div><a id="more"></a><div class="sect1"><h2>Back-Pressure</h2><div class="sectionbody"><div class="paragraph"><p>This is how it&#8217;s defined in <a href="https://www.reactivemanifesto.org/glossary#Back-Pressure" target="_blank" rel="noopener">Reactive Manifesto</a>:</p></div><div class="quoteblock"><blockquote><div class="paragraph"><p><strong>Back-Pressure</strong></p></div><div class="paragraph"><p>When one component is struggling to keep-up, the system as a whole needs to respond in a sensible way. It is unacceptable for the component under stress to fail catastrophically or to drop messages in an uncontrolled fashion. Since it cant cope and it cant fail it should communicate the fact that it is under stress to upstream components and so get them to reduce the load. This back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load, and will provide information that may allow the system itself to apply other resources to help distribute the load.</p></div></blockquote></div><div class="paragraph"><p>Let&#8217;s illustrate the context, that requires to apply back-pressure.</p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/backpressure.png"><img src="/images/backpressure.png" alt="backpressure"></a></div></div></div></div><div class="paragraph"><p>So, essentially the problem here is the mismatch in throughput between services.</p></div></div></div><div class="sect1"><h2>Strategies to deal with throughput mismatch</h2><div class="sectionbody"><div class="paragraph"><p>There are several strategies to deal with throughput mismatch:</p></div><div class="ulist"><ul><li><p><em>Auto-scale</em> service, that is under pressure</p></li><li><p><em>Drop down (or sample)</em> incoming requests, once service under pressure is saturated</p></li><li><p><em>Buffer</em> requests</p></li><li><p><em>Control</em> the request producer</p></li></ul></div><div class="sect2"><h3>Auto-scaling</h3><div class="paragraph"><p>Probably, auto-scaling is the easiest way to deal with the problem. E.g. in the example above the solution would be to scale the <strong>service B</strong> up - this definitely will resolve throughput deficit. In some cases this will be just enough, but in other - auto-scaling might lead to propagating the problem to the next service (e.g. <strong>service C</strong>). Also, if you are in severe cost/hardware deficit, scaling up is simply not feasible.</p></div></div><div class="sect2"><h3>Dropping down or sampling</h3><div class="paragraph"><p>Only some fraction of incoming requests is processed, other are simply ignored. E.g. in the example above to solve the problem it would be enough for <strong>service B</strong> to just skip processing every 3rd request. However, most often it&#8217;s not applicable in practice</p></div></div><div class="sect2"><h3>Buffering requests</h3><div class="paragraph"><p>Probably, applying buffer is the most intuitive thing to do. E.g. in the example above this approach can be implemented by introducing messaging queue between <strong>service A and B</strong> or, alternatively, storing incoming request to the database. This, in essence, allows <strong>service B</strong> to pull requests from buffer, when it&#8217;s ready to process them. However, beside the complication in infrastructure it&#8217;s not always possible, since not all requests might be processed asynchronously.</p></div></div><div class="sect2"><h3>Controlling the request producer</h3><div class="paragraph"><p>Controlling the request producer is, actually, defined as"back-pressure" by Reactive Manifesto. In the example above it means, that <strong>service B</strong> should be able to slow down/speed up <strong>service A</strong>. So, <strong>service A</strong> should not <em>push</em> requests to <strong>service B</strong>, instead <strong>service B</strong> should <em>pull</em> desired number of requests from <strong>service A</strong>. However, controlling producer speed is not always an option (imaging telling your user to slow down). Also, back-pressure mechanism introduces complexity in the system, so should be decided carefully.</p></div></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="paragraph"><p>Whenever there is a mismatch in throughput between services there might be the opportunity to apply back-pressure pattern.</p></div><div class="paragraph"><p>What strategy should be applied really depends on the constraints and requirements at hand.</p></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;Back-pressure is an important feedback mechanism that allows systems to gracefully respond to load rather than collapse under it. The back-pressure may cascade all the way up to the user, at which point responsiveness may degrade, but this mechanism will ensure that the system is resilient under load.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Reactive" scheme="https://www.oxymorus.com/categories/reactive/"/>
    
      <category term="Back-Pressure" scheme="https://www.oxymorus.com/categories/reactive/back-pressure/"/>
    
    
      <category term="back-pressure" scheme="https://www.oxymorus.com/tags/back-pressure/"/>
    
  </entry>
  
  <entry>
    <title>Blocking vs Not-Blocking</title>
    <link href="https://www.oxymorus.com/blocking-vs-nonblocking/"/>
    <id>https://www.oxymorus.com/blocking-vs-nonblocking/</id>
    <published>2019-06-18T14:45:13.000Z</published>
    <updated>2019-10-17T22:50:07.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>An important aspect of 'reactive&#8217;approach to concurrent programming is non-blocking processing. This post compares blocking vs non-blocking processing in general terms to highlight&#8217;reactive' idea in a nutshell.</p></div><a id="more"></a><div class="sect1"><h2>Blocking Processing</h2><div class="sectionbody"><div class="paragraph"><p>Blocking (synchronous) processing has several characteristics:</p></div><div class="ulist"><ul><li><p>Bound to the processing thread</p></li><li><p>Processing thread is waiting in case any I/O operation is performed</p></li></ul></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/blocking-processing.svg"><img src="/images/blocking-processing.svg" alt="blocking processing"></a></div></div></div></div><div class="paragraph"><p>Under highload this approach has following consequences:</p></div><div class="ulist"><ul><li><p><strong>CPU &amp; RAM resources are wasted</strong>, while thread is waiting to the I/O results.</p></li><li><p>If all threads are waiting, new user requests are either put to the queue or dropped down. This leads to poor user experience.</p></li><li><p>If all threads are waiting, service becomes unresponsive for API clients. This leads to timeouts and API clients failure. Basically, <strong>failure leads to more failure</strong>.</p></li></ul></div></div></div><div class="sect1"><h2>Non-Blocking Processing</h2><div class="sectionbody"><div class="paragraph"><p>Non-Blocking (aka "reactive") processing has several characteristics:</p></div><div class="ulist"><ul><li><p>Not bound to specific processing thread</p></li><li><p><strong>Threads are not waiting</strong> in case I/O operation is performed</p></li><li><p>Threads are reused between calls</p></li></ul></div><div class="paragraph"><p><span class="image"><img src="/img/non_blocking_processing.png" alt="Non-blocking processing"></span></p></div><div class="openblock text-center"><div class="content"><div class="imageblock img-responsive img-thumbnail"><div class="content"><a class="image" href="/images/nonblocking-processing.svg"><img src="/images/nonblocking-processing.svg" alt="nonblocking processing"></a></div></div></div></div><div class="paragraph"><p>Under highload this approach has following consequences:</p></div><div class="ulist"><ul><li><p>High CPU &amp; RAM utilization</p></li><li><p>Less threads are needed to serve same number of requests as in blocking case</p></li></ul></div><div class="paragraph"><p>However, non-blocking procesing comes with a cost:</p></div><div class="ulist"><ul><li><p>Backend design is complicated, since the need to track origin and arrival of responses &amp; errors (also errors may be unnoticed). This require new design patterns to be employed (hopefully, wrapped into frameworks like <a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html" target="_blank" rel="noopener">Spring WebFlux</a>).</p></li><li><p>Frontend design is complicated, since response(s) will come asynchronously via <a href="https://en.wikipedia.org/wiki/WebSocket" target="_blank" rel="noopener">websockets</a>, <a href="https://en.wikipedia.org/wiki/Server-sent_events" target="_blank" rel="noopener">server-sent events</a>, etc.</p></li></ul></div></div></div><div class="sect1"><h2>Conclusion</h2><div class="sectionbody"><div class="ulist"><ul><li><p>In both cases response time is limited by I/O operations (filesystem, database, network) and response time of downstream services.</p></li><li><p>Threads used for non-blocking processing don&#8217;t wait for I/O operations to complete. This gives better resource utilization and increases throughput, compared to blocking processing.</p></li></ul></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;An important aspect of &#39;reactive&amp;#8217;approach to concurrent programming is non-blocking processing. This post compares blocking vs non-blocking processing in general terms to highlight&amp;#8217;reactive&#39; idea in a nutshell.&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Reactive" scheme="https://www.oxymorus.com/categories/reactive/"/>
    
      <category term="Blocking processing" scheme="https://www.oxymorus.com/categories/reactive/blocking-processing/"/>
    
      <category term="Non-blocking processing" scheme="https://www.oxymorus.com/categories/reactive/blocking-processing/non-blocking-processing/"/>
    
    
      <category term="Reactive" scheme="https://www.oxymorus.com/tags/reactive/"/>
    
      <category term="Blocking processing" scheme="https://www.oxymorus.com/tags/blocking-processing/"/>
    
      <category term="Non-blocking processing" scheme="https://www.oxymorus.com/tags/non-blocking-processing/"/>
    
  </entry>
  
  <entry>
    <title>Trick Of The Day: Cloning all Github repositories</title>
    <link href="https://www.oxymorus.com/clone-all-github-repos/"/>
    <id>https://www.oxymorus.com/clone-all-github-repos/</id>
    <published>2019-06-17T22:52:55.000Z</published>
    <updated>2019-10-07T22:52:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to clone all github repositories for specific organization?</p></div><a id="more"></a><div class="sect1"><h2>Situation</h2><div class="sectionbody"><div class="paragraph"><p>You need to clone all repos for your organization on github/on-premise github. Since there might be plenty of repos you don&#8217;t want to repeat yourself and prefer automate this process.</p></div></div></div><div class="sect1"><h2>Solution</h2><div class="sectionbody"><div class="ulist"><ul><li><p>Create an API token by going to Account Settings &#8594; Applications</p></li><li><p>Clone repos:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ GITHUB_BASE_URL={api.github.com|yourcompanygithub}; CONTEXT={users|orgs}; NAME={username|orgname}; ACCESS_TOKEN={yourtoken}$ curl "https://$GITHUB_BASE_URL/api/v3/$CONTEXT/$NAME/repos?page=1&amp;per_page=100&amp;access_token=$ACCESS_TOKEN" \     | jq '.[] | .clone_url' \     | xargs -L1 git clone</code></pre></div></div><div class="paragraph"><p><strong>Notes:</strong></p></div><div class="olist arabic"><ol class="arabic"><li><p><em>CONTEXT=users</em> and <em>NAME=yourusername</em> will clone all your repositories.</p></li><li><p><em>CONTEXT=orgs</em> and <em>NAME=yourorgname</em> will clone all repositories of your organization.</p></li><li><p>The solutions assumes you have <a href="https://stedolan.github.io/jq/manual/" target="_blank" rel="noopener">jq</a> installed. <em>If you haven&#8217;t, it&#8217;s time to do it.</em></p></li></ol></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to clone all github repositories for specific organization?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Github" scheme="https://www.oxymorus.com/categories/github/"/>
    
      <category term="clone" scheme="https://www.oxymorus.com/categories/github/clone/"/>
    
      <category term="jq" scheme="https://www.oxymorus.com/categories/github/clone/jq/"/>
    
    
      <category term="Github" scheme="https://www.oxymorus.com/tags/github/"/>
    
      <category term="clone" scheme="https://www.oxymorus.com/tags/clone/"/>
    
      <category term="jq" scheme="https://www.oxymorus.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Trick Of The Day: Copy DB dump from one Docker container to another</title>
    <link href="https://www.oxymorus.com/docker-mysql-dump/"/>
    <id>https://www.oxymorus.com/docker-mysql-dump/</id>
    <published>2019-04-23T22:52:55.000Z</published>
    <updated>2019-04-23T22:52:55.000Z</updated>
    
    <content type="html"><![CDATA[<div class="paragraph"><p>How to copy MySQL dump from one Docker container to another ?</p></div><a id="more"></a><div class="sect1"><h2>Situation</h2><div class="sectionbody"><div class="paragraph"><p>You need to create DB dump in one Docker container and apply it in another Docker container.</p></div></div></div><div class="sect1"><h2>Application</h2><div class="sectionbody"><div class="paragraph"><p>Crate DB dump on staging env and apply it on local env to experiment with existing database.</p></div></div></div><div class="sect1"><h2>Solution</h2><div class="sectionbody"><div class="ulist"><ul><li><p>Connect to first container:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ docker exec -ti mysql-staging /bin/bash</code></pre></div></div><div class="ulist"><ul><li><p>Create DB dump:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ mysqldump -u user -p --databases db &gt; /tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Copy dump to localhost:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh"># general syntax:# docker cp CONTAINER:SRC_PATH DEST_PATH$ docker cp mysql:/tmp/db.sql /tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Copy dump to second container:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh"># general syntax:# docker cp DEST_PATH CONTAINER:SRC_PATH$ docker cp /tmp/db.sql mysql:/tmp/db.sql</code></pre></div></div><div class="ulist"><ul><li><p>Apply DB dump:</p></li></ul></div><div class="listingblock"><div class="content"><pre class="highlightjs highlight"><code class="language-sh hljs" data-lang="sh">$ docker exec -ti mysql /bin/bash$ mysql -u user -p-- Run the backup script to recreate the databasemysql&gt; drop database if exists db;mysql&gt; source /tmp/db.sql</code></pre></div></div></div></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;paragraph&quot;&gt;&lt;p&gt;How to copy MySQL dump from one Docker container to another ?&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://www.oxymorus.com/categories/docker/"/>
    
      <category term="MySQL" scheme="https://www.oxymorus.com/categories/docker/mysql/"/>
    
      <category term="dump" scheme="https://www.oxymorus.com/categories/docker/mysql/dump/"/>
    
    
      <category term="Docker" scheme="https://www.oxymorus.com/tags/docker/"/>
    
      <category term="MySQL" scheme="https://www.oxymorus.com/tags/mysql/"/>
    
  </entry>
  
</feed>
